{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3Xf5UH8T5C8"
      },
      "source": [
        "# Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "5Yczhqi41FmV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "collapsed": true,
        "outputId": "cfece205-994c-4364-88e1-4b5f58a301cc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-0f6d3514c078>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Mount Google Drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    131\u001b[0m   )\n\u001b[1;32m    132\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "W3FtYqYoYEj9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsWpJFthsGYZ"
      },
      "source": [
        "# Ignore Warning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3js21ldgsH9j"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "\n",
        "# Ignore all warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnA0X7PCAubW"
      },
      "source": [
        "# Install packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "3H6xXKCkAwL1",
        "outputId": "a2a040e7-47d4-4cd0-846c-796094db9da7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mne in /usr/local/lib/python3.10/dist-packages (1.7.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from mne) (3.1.4)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.10/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from mne) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from mne) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mne) (24.1)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.10/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from mne) (1.11.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mne) (4.66.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (2.8.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (4.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (2.31.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->mne) (2.1.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.5.0->mne) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2024.6.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install mne"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LQdQepn815q"
      },
      "source": [
        "# Create a Specific Folder in Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uFECHC-Q83Vm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Define the folder path\n",
        "folder_path = '/content/drive/MyDrive/MyOutput'\n",
        "\n",
        "# Create the folder if it doesn't exist\n",
        "if not os.path.exists(folder_path):\n",
        "    os.makedirs(folder_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mz5kvQu7WA_"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load and Inspect the numpy File"
      ],
      "metadata": {
        "id": "Uzg73qRQFgqv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "LXBGU4lKD7zs",
        "outputId": "6d6658fc-b5a6-4961-d930-6a3f35ec5a7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['features', 'labels']\n",
            "features\n",
            "[[-1.90870635 -0.29377429 -0.40836448 ... -0.86416276 -0.67967745\n",
            "  -0.87754483]\n",
            " [ 0.19074051 -0.48813012  0.07289046 ...  0.14512032 -0.30840483\n",
            "  -0.93400415]\n",
            " [-1.54598618 -0.758312   -0.63416532 ... -0.41448695 -0.45770711\n",
            "  -0.81797092]\n",
            " ...\n",
            " [-1.24999741 -1.43994603 -0.81837836 ... -1.48299788 -1.37180942\n",
            "  -1.13992731]\n",
            " [-1.25960391 -1.37920593 -1.45633972 ... -1.50528596 -1.46905574\n",
            "  -1.02324979]\n",
            " [-1.31036863 -0.94014314 -0.756988   ... -1.08614067 -0.74169381\n",
            "  -1.04778939]]\n",
            "labels\n",
            "[[351788      1      1      1]\n",
            " [358546      1      1      1]\n",
            " [365390      3      1      1]\n",
            " ...\n",
            " [945512      2      1      3]\n",
            " [952253      2      1      3]\n",
            " [959079      1      1      3]]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Load the .npz file\n",
        "data = np.load('/content/CombinedFile_6Subjects_50_testing_CSP_Features.npz')\n",
        "\n",
        "# List all arrays in the .npz file\n",
        "print(data.files)\n",
        "\n",
        "# Access and print each array\n",
        "\n",
        "for array_name in data.files:\n",
        "    print(array_name)\n",
        "    print(data[array_name])\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['labels'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SarxxSdxXIh",
        "outputId": "0ee7a906-402b-4ea7-b9fa-e3bac765eafe"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1316, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels= data['labels']\n",
        "labels= labels[:, 1]\n",
        "labels.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmHbl4wT2Pkk",
        "outputId": "d89cd9dd-5e09-4525-cf63-8320b7ac37d7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1316,)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "unique, frequency = np.unique(labels,\n",
        "                              return_counts = True)\n",
        "\n",
        "# convert both into one numpy array\n",
        "count = np.asarray((unique, frequency ))\n",
        "\n",
        "print(\"The values and their frequency are:\\n\",\n",
        "     count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btqxzOiAwm4F",
        "outputId": "cb003857-7c41-47a3-d3ed-4aa2f70fc8c4"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The values and their frequency are:\n",
            " [[  0   1   2   3]\n",
            " [329 329 329 329]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Data Cleaning and preparation for numpy files**"
      ],
      "metadata": {
        "id": "Zffe_bbxFYML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import joblib\n",
        "\n",
        "\n",
        "# Assuming 'Feature' and 'Label' are keys in the npz file\n",
        "features = data['features']\n",
        "\n",
        "# Function to clean feature strings\n",
        "def clean_feature_string(feature_str):\n",
        "    if isinstance(feature_str, str):\n",
        "        cleaned = feature_str.strip('[]').replace(' ', ',').replace('\\n', '')\n",
        "        return cleaned.split(',') if cleaned else []\n",
        "    return feature_str  # If it's already a list or array, return as is\n",
        "\n",
        "# Convert the feature strings to lists of floats\n",
        "cleaned_features = []\n",
        "for feature in features:\n",
        "    cleaned_feature = clean_feature_string(feature)\n",
        "    if len(cleaned_feature) == 0:\n",
        "        cleaned_feature = [0.0] * 10  # Handle empty features by filling with placeholder\n",
        "    cleaned_features.append([float(i) for i in cleaned_feature])\n",
        "\n",
        "# Convert cleaned_features to a numpy array\n",
        "X = np.array(cleaned_features)\n",
        "y=labels\n",
        "# Optional: Split the data into training and testing sets\n",
        "\n",
        "'''\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert labels to categorical (if using TensorFlow/Keras)\n",
        "num_classes = len(np.unique(y))\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes=num_classes)\n",
        "\n",
        "print(\"First few rows of scaled features:\")\n",
        "print(X_train[:5])\n",
        "print(\"First few labels (one-hot encoded):\")\n",
        "print(y_train[:5])\n",
        "\n",
        "print(\"Data cleaning and preparation complete.\")\n",
        "'''\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "Ec7WbHs7YzR0",
        "outputId": "9bcd5899-30b5-4acd-a4cb-fdea4991eb6d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n\\n# Convert labels to categorical (if using TensorFlow/Keras)\\nnum_classes = len(np.unique(y))\\ny_train = tf.keras.utils.to_categorical(y_train, num_classes=num_classes)\\ny_test = tf.keras.utils.to_categorical(y_test, num_classes=num_classes)\\n\\nprint(\"First few rows of scaled features:\")\\nprint(X_train[:5])\\nprint(\"First few labels (one-hot encoded):\")\\nprint(y_train[:5])\\n\\nprint(\"Data cleaning and preparation complete.\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3DpjxkMQXSc",
        "outputId": "4dafbf88-6640-46f9-c4a8-ed52cb5d8570"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1316, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "nC4CaRz-llMs"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import RobustScaler\n",
        "scaler=RobustScaler()\n",
        "features_resampled_scaled = scaler.fit_transform(X_train)\n",
        "features_test_scaled = scaler.transform(X_test)  # Use the same scaler to transform test data\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "evNOlXz3NLXh"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_resampled_scaled.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YSRGbyB8evr",
        "outputId": "64d613a2-7881-40a1-ee63-f1b8d80d9741"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1052, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "num_classes = len(np.unique(y_train))\n",
        "labels_resampled = tf.keras.utils.to_categorical(y_train, num_classes=num_classes)\n",
        "labels_resampled"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-wQoDakJuEP",
        "outputId": "d26cedd8-66d2-445f-c8f1-8d8ef3cb4ea4"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 1., 0.],\n",
              "       [0., 1., 0., 0.],\n",
              "       [0., 0., 0., 1.],\n",
              "       ...,\n",
              "       [1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(np.unique(y_test))\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes=num_classes)\n",
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFJTfxNGw9HQ",
        "outputId": "feaf6434-f25c-417c-8f60-3832df72c68c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 1., 0.],\n",
              "       [0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0.],\n",
              "       ...,\n",
              "       [1., 0., 0., 0.],\n",
              "       [1., 0., 0., 0.],\n",
              "       [1., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CNN** **MODEL**"
      ],
      "metadata": {
        "id": "Fr41ZIDqcmVI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization,GlobalAveragePooling1D\n",
        "from tensorflow.keras.regularizers import l2\n",
        "import random\n",
        "\n",
        "\n",
        "\n",
        "np.random.seed(2017)\n",
        "\n",
        "\n",
        "# Reshape the features for CNN input\n",
        "X_train_reshaped = features_resampled_scaled.reshape(features_resampled_scaled.shape[0], features_resampled_scaled.shape[1], 1)\n",
        "X_test_reshaped = features_test_scaled.reshape(features_test_scaled.shape[0], features_test_scaled.shape[1], 1)\n",
        "\n",
        "\n",
        "\n",
        "model =  Sequential([\n",
        "    Conv1D(128, 3, activation='relu', input_shape=(X_train_reshaped.shape[1], 1),kernel_regularizer=l2(0.01)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Dropout(0.7),\n",
        "\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.7),\n",
        "    Dense(num_classes, activation='softmax')  # Adjust the output layer based on the number of classes\n",
        "])\n",
        "\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Convert one-hot encoded labels back to original class labels\n",
        "y_train_classes = np.argmax(labels_resampled, axis=1)\n",
        "\n",
        "# Compute class weights\n",
        "\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(y_train_classes), y=y_train_classes)\n",
        "class_weights_dict = dict(enumerate(class_weights))\n",
        "\n",
        "# Adjust class weights moderately\n",
        "for key in class_weights_dict:\n",
        "    class_weights_dict[key] = class_weights_dict[key] * 1.25  # Increase weights moderately\n",
        "\n",
        "\n",
        "# Evaluate the model\n",
        "\n",
        "# Model summary\n",
        "model.summary()\n",
        "\n",
        "# Early stopping to prevent overfitting\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train_reshaped, labels_resampled, validation_data=(X_test_reshaped, y_test),\n",
        "                    epochs=200, batch_size=32, callbacks=[early_stopping],shuffle=False, verbose=2)#class_weight=class_weights_dict)\n",
        "\n",
        "# Define the file path where the model will be saved\n",
        "model_file_path = os.path.join(folder_path, 'tested_3_cnn_model')\n",
        "\n",
        "\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test, verbose=0)\n",
        "print(f'CNN Model Accuracy: {accuracy:.2%}')\n",
        "\n",
        "# Make predictions and evaluate\n",
        "y_pred = model.predict(X_test_reshaped)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_test_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Generate a classification report\n",
        "from sklearn.metrics import classification_report\n",
        "report = classification_report(y_test_classes, y_pred_classes)\n",
        "print('CNN Model Classification Report:')\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSYh-DG8XtOZ",
        "outputId": "092bbb36-e563-4bac-ea3d-26f3dabb5611"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_2 (Conv1D)           (None, 48, 128)           512       \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 48, 128)           512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling1d_2 (MaxPoolin  (None, 24, 128)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 24, 128)           0         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 3072)              0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 128)               393344    \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 4)                 516       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 394884 (1.51 MB)\n",
            "Trainable params: 394628 (1.51 MB)\n",
            "Non-trainable params: 256 (1.00 KB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "33/33 - 2s - loss: 3.8786 - accuracy: 0.3004 - val_loss: 1.3688 - val_accuracy: 0.4091 - 2s/epoch - 54ms/step\n",
            "Epoch 2/200\n",
            "33/33 - 0s - loss: 2.0394 - accuracy: 0.4183 - val_loss: 1.3832 - val_accuracy: 0.4394 - 451ms/epoch - 14ms/step\n",
            "Epoch 3/200\n",
            "33/33 - 1s - loss: 1.4869 - accuracy: 0.4344 - val_loss: 1.3893 - val_accuracy: 0.4432 - 708ms/epoch - 21ms/step\n",
            "Epoch 4/200\n",
            "33/33 - 1s - loss: 1.2716 - accuracy: 0.4829 - val_loss: 1.3855 - val_accuracy: 0.4394 - 704ms/epoch - 21ms/step\n",
            "Epoch 5/200\n",
            "33/33 - 1s - loss: 1.1849 - accuracy: 0.5114 - val_loss: 1.3665 - val_accuracy: 0.5189 - 674ms/epoch - 20ms/step\n",
            "Epoch 6/200\n",
            "33/33 - 1s - loss: 1.1286 - accuracy: 0.5247 - val_loss: 1.3428 - val_accuracy: 0.5379 - 707ms/epoch - 21ms/step\n",
            "Epoch 7/200\n",
            "33/33 - 1s - loss: 1.1125 - accuracy: 0.5380 - val_loss: 1.3094 - val_accuracy: 0.6023 - 733ms/epoch - 22ms/step\n",
            "Epoch 8/200\n",
            "33/33 - 1s - loss: 1.0485 - accuracy: 0.5447 - val_loss: 1.2763 - val_accuracy: 0.6212 - 520ms/epoch - 16ms/step\n",
            "Epoch 9/200\n",
            "33/33 - 0s - loss: 1.0328 - accuracy: 0.5675 - val_loss: 1.2351 - val_accuracy: 0.6136 - 466ms/epoch - 14ms/step\n",
            "Epoch 10/200\n",
            "33/33 - 0s - loss: 1.0353 - accuracy: 0.5713 - val_loss: 1.1825 - val_accuracy: 0.6667 - 419ms/epoch - 13ms/step\n",
            "Epoch 11/200\n",
            "33/33 - 0s - loss: 0.9923 - accuracy: 0.5798 - val_loss: 1.1200 - val_accuracy: 0.6667 - 392ms/epoch - 12ms/step\n",
            "Epoch 12/200\n",
            "33/33 - 0s - loss: 0.9300 - accuracy: 0.6084 - val_loss: 1.0707 - val_accuracy: 0.6515 - 442ms/epoch - 13ms/step\n",
            "Epoch 13/200\n",
            "33/33 - 0s - loss: 0.9120 - accuracy: 0.6207 - val_loss: 0.9859 - val_accuracy: 0.6629 - 445ms/epoch - 13ms/step\n",
            "Epoch 14/200\n",
            "33/33 - 0s - loss: 0.9627 - accuracy: 0.5979 - val_loss: 0.9559 - val_accuracy: 0.6818 - 429ms/epoch - 13ms/step\n",
            "Epoch 15/200\n",
            "33/33 - 0s - loss: 0.8846 - accuracy: 0.6141 - val_loss: 0.9019 - val_accuracy: 0.6970 - 441ms/epoch - 13ms/step\n",
            "Epoch 16/200\n",
            "33/33 - 0s - loss: 0.8833 - accuracy: 0.6179 - val_loss: 0.8607 - val_accuracy: 0.7121 - 461ms/epoch - 14ms/step\n",
            "Epoch 17/200\n",
            "33/33 - 0s - loss: 0.8627 - accuracy: 0.6473 - val_loss: 0.8293 - val_accuracy: 0.6591 - 409ms/epoch - 12ms/step\n",
            "Epoch 18/200\n",
            "33/33 - 0s - loss: 0.8542 - accuracy: 0.6388 - val_loss: 0.8305 - val_accuracy: 0.6553 - 414ms/epoch - 13ms/step\n",
            "Epoch 19/200\n",
            "33/33 - 0s - loss: 0.8064 - accuracy: 0.6511 - val_loss: 0.8190 - val_accuracy: 0.6629 - 462ms/epoch - 14ms/step\n",
            "Epoch 20/200\n",
            "33/33 - 0s - loss: 0.7995 - accuracy: 0.6616 - val_loss: 0.7699 - val_accuracy: 0.6818 - 399ms/epoch - 12ms/step\n",
            "Epoch 21/200\n",
            "33/33 - 0s - loss: 0.7888 - accuracy: 0.6587 - val_loss: 0.7559 - val_accuracy: 0.6932 - 476ms/epoch - 14ms/step\n",
            "Epoch 22/200\n",
            "33/33 - 0s - loss: 0.8076 - accuracy: 0.6540 - val_loss: 0.7426 - val_accuracy: 0.7159 - 457ms/epoch - 14ms/step\n",
            "Epoch 23/200\n",
            "33/33 - 0s - loss: 0.8499 - accuracy: 0.6502 - val_loss: 0.7527 - val_accuracy: 0.7273 - 429ms/epoch - 13ms/step\n",
            "Epoch 24/200\n",
            "33/33 - 0s - loss: 0.7777 - accuracy: 0.6616 - val_loss: 0.7414 - val_accuracy: 0.6932 - 422ms/epoch - 13ms/step\n",
            "Epoch 25/200\n",
            "33/33 - 0s - loss: 0.7227 - accuracy: 0.6939 - val_loss: 0.7242 - val_accuracy: 0.7159 - 414ms/epoch - 13ms/step\n",
            "Epoch 26/200\n",
            "33/33 - 0s - loss: 0.8168 - accuracy: 0.6473 - val_loss: 0.7474 - val_accuracy: 0.7159 - 449ms/epoch - 14ms/step\n",
            "Epoch 27/200\n",
            "33/33 - 0s - loss: 0.7400 - accuracy: 0.6806 - val_loss: 0.7132 - val_accuracy: 0.7159 - 400ms/epoch - 12ms/step\n",
            "Epoch 28/200\n",
            "33/33 - 0s - loss: 0.7442 - accuracy: 0.6806 - val_loss: 0.7156 - val_accuracy: 0.7121 - 432ms/epoch - 13ms/step\n",
            "Epoch 29/200\n",
            "33/33 - 0s - loss: 0.7360 - accuracy: 0.6987 - val_loss: 0.7193 - val_accuracy: 0.7273 - 456ms/epoch - 14ms/step\n",
            "Epoch 30/200\n",
            "33/33 - 0s - loss: 0.6866 - accuracy: 0.7082 - val_loss: 0.7066 - val_accuracy: 0.7045 - 454ms/epoch - 14ms/step\n",
            "Epoch 31/200\n",
            "33/33 - 1s - loss: 0.6922 - accuracy: 0.6930 - val_loss: 0.7204 - val_accuracy: 0.7273 - 641ms/epoch - 19ms/step\n",
            "Epoch 32/200\n",
            "33/33 - 1s - loss: 0.7427 - accuracy: 0.6911 - val_loss: 0.7255 - val_accuracy: 0.7197 - 721ms/epoch - 22ms/step\n",
            "Epoch 33/200\n",
            "33/33 - 1s - loss: 0.6791 - accuracy: 0.7053 - val_loss: 0.7067 - val_accuracy: 0.7348 - 689ms/epoch - 21ms/step\n",
            "Epoch 34/200\n",
            "33/33 - 1s - loss: 0.7149 - accuracy: 0.6882 - val_loss: 0.7039 - val_accuracy: 0.7197 - 707ms/epoch - 21ms/step\n",
            "Epoch 35/200\n",
            "33/33 - 1s - loss: 0.6915 - accuracy: 0.6977 - val_loss: 0.6963 - val_accuracy: 0.7159 - 706ms/epoch - 21ms/step\n",
            "Epoch 36/200\n",
            "33/33 - 1s - loss: 0.6553 - accuracy: 0.7300 - val_loss: 0.6720 - val_accuracy: 0.7311 - 629ms/epoch - 19ms/step\n",
            "Epoch 37/200\n",
            "33/33 - 1s - loss: 0.6723 - accuracy: 0.7091 - val_loss: 0.6645 - val_accuracy: 0.7614 - 863ms/epoch - 26ms/step\n",
            "Epoch 38/200\n",
            "33/33 - 1s - loss: 0.6253 - accuracy: 0.7224 - val_loss: 0.6646 - val_accuracy: 0.7424 - 547ms/epoch - 17ms/step\n",
            "Epoch 39/200\n",
            "33/33 - 0s - loss: 0.6592 - accuracy: 0.7215 - val_loss: 0.6818 - val_accuracy: 0.7159 - 440ms/epoch - 13ms/step\n",
            "Epoch 40/200\n",
            "33/33 - 0s - loss: 0.6224 - accuracy: 0.7310 - val_loss: 0.6936 - val_accuracy: 0.7348 - 408ms/epoch - 12ms/step\n",
            "Epoch 41/200\n",
            "33/33 - 0s - loss: 0.6240 - accuracy: 0.7367 - val_loss: 0.6994 - val_accuracy: 0.7311 - 453ms/epoch - 14ms/step\n",
            "Epoch 42/200\n",
            "33/33 - 0s - loss: 0.6301 - accuracy: 0.7329 - val_loss: 0.7016 - val_accuracy: 0.7348 - 460ms/epoch - 14ms/step\n",
            "Epoch 43/200\n",
            "33/33 - 0s - loss: 0.6663 - accuracy: 0.7205 - val_loss: 0.6870 - val_accuracy: 0.7197 - 436ms/epoch - 13ms/step\n",
            "Epoch 44/200\n",
            "33/33 - 0s - loss: 0.6440 - accuracy: 0.7120 - val_loss: 0.6752 - val_accuracy: 0.7386 - 393ms/epoch - 12ms/step\n",
            "Epoch 45/200\n",
            "33/33 - 0s - loss: 0.6281 - accuracy: 0.7215 - val_loss: 0.6799 - val_accuracy: 0.7386 - 413ms/epoch - 13ms/step\n",
            "Epoch 46/200\n",
            "33/33 - 0s - loss: 0.6450 - accuracy: 0.7262 - val_loss: 0.6797 - val_accuracy: 0.7386 - 445ms/epoch - 13ms/step\n",
            "Epoch 47/200\n",
            "33/33 - 0s - loss: 0.6827 - accuracy: 0.7186 - val_loss: 0.6891 - val_accuracy: 0.7386 - 430ms/epoch - 13ms/step\n",
            "CNN Model Accuracy: 76.14%\n",
            "9/9 [==============================] - 0s 5ms/step\n",
            "CNN Model Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.75      0.81        71\n",
            "           1       0.77      0.79      0.78        70\n",
            "           2       0.77      0.72      0.75        61\n",
            "           3       0.64      0.79      0.71        62\n",
            "\n",
            "    accuracy                           0.76       264\n",
            "   macro avg       0.77      0.76      0.76       264\n",
            "weighted avg       0.77      0.76      0.76       264\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['loss'],label='train')\n",
        "plt.plot(history.history['val_loss'],label='test')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "PaEWarM-5PU0",
        "outputId": "df609949-5a18-411a-a758-56815eb57e01"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51EeF9mFWPEq"
      },
      "source": [
        "# Updated model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFWYKwnOuzK_"
      },
      "source": [
        "## Save the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "UMHb_x6Duy7E"
      },
      "outputs": [],
      "source": [
        "# Save the model\n",
        "model.save(model_file_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u88reoKtvSkI"
      },
      "source": [
        "## K-fold |Model 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import classification_report\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Ensure your data is already loaded and prepared\n",
        "\n",
        "# K-Fold Cross Validation\n",
        "num_folds = 5\n",
        "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
        "\n",
        "# Define arrays to store results\n",
        "fold_no = 1\n",
        "losses = []\n",
        "accuracies = []\n",
        "\n",
        "X = features_resampled_scaled\n",
        "y = labels_resampled\n",
        "\n",
        "for train_index, val_index in kf.split(X):\n",
        "    X_train_fold, X_val_fold = X[train_index], X[val_index]\n",
        "    y_train_fold, y_val_fold = y[train_index], y[val_index]\n",
        "\n",
        "    # Reshape for CNN input\n",
        "    X_train_fold = X_train_fold.reshape(X_train_fold.shape[0], X_train_fold.shape[1], 1)\n",
        "    X_val_fold = X_val_fold.reshape(X_val_fold.shape[0], X_val_fold.shape[1], 1)\n",
        "\n",
        "    # Convert one-hot encoded labels back to original class labels for class weight calculation\n",
        "    y_train_classes = np.argmax(y_train_fold, axis=1)\n",
        "\n",
        "    # Compute class weights\n",
        "    class_weights = compute_class_weight('balanced', classes=np.unique(y_train_classes), y=y_train_classes)\n",
        "    class_weights_dict = dict(enumerate(class_weights))\n",
        "\n",
        "    # Adjust class weights moderately\n",
        "    for key in class_weights_dict:\n",
        "        class_weights_dict[key] = class_weights_dict[key] * 1.25\n",
        "\n",
        "    # Define the CNN model\n",
        "    model = Sequential([\n",
        "        Conv1D(128, 3, activation='relu', input_shape=(X_train_fold.shape[1], 1), kernel_regularizer=l2(0.01)),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Dropout(0.7),\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.7),\n",
        "        Dense(y_train_fold.shape[1], activation='softmax')  # Adjust the output layer based on the number of classes\n",
        "    ])\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Early stopping to prevent overfitting\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(X_train_fold, y_train_fold, validation_data=(X_val_fold, y_val_fold),\n",
        "                        epochs=100, batch_size=32, callbacks=[early_stopping], verbose=2, class_weight=class_weights_dict)\n",
        "\n",
        "    # Evaluate the model\n",
        "    loss, accuracy = model.evaluate(X_val_fold, y_val_fold, verbose=0)\n",
        "    print(f'Fold {fold_no} - Loss: {loss:.4f}, Accuracy: {accuracy:.2%}')\n",
        "\n",
        "    losses.append(loss)\n",
        "    accuracies.append(accuracy)\n",
        "\n",
        "    fold_no += 1\n",
        "\n",
        "# Print average scores\n",
        "print(f'Average Loss across all folds: {np.mean(losses):.4f}')\n",
        "print(f'Average Accuracy across all folds: {np.mean(accuracies):.2%}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "863UGOxxWxed",
        "outputId": "02753066-9749-4f94-fc9a-f3f311af7f6c"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "27/27 - 2s - loss: 5.1692 - accuracy: 0.2723 - val_loss: 1.3780 - val_accuracy: 0.4550 - 2s/epoch - 87ms/step\n",
            "Epoch 2/100\n",
            "27/27 - 0s - loss: 2.7787 - accuracy: 0.4067 - val_loss: 1.3855 - val_accuracy: 0.4502 - 182ms/epoch - 7ms/step\n",
            "Epoch 3/100\n",
            "27/27 - 0s - loss: 2.0041 - accuracy: 0.4185 - val_loss: 1.3900 - val_accuracy: 0.4171 - 216ms/epoch - 8ms/step\n",
            "Epoch 4/100\n",
            "27/27 - 0s - loss: 1.7847 - accuracy: 0.4685 - val_loss: 1.3900 - val_accuracy: 0.4171 - 195ms/epoch - 7ms/step\n",
            "Epoch 5/100\n",
            "27/27 - 0s - loss: 1.5345 - accuracy: 0.4863 - val_loss: 1.3831 - val_accuracy: 0.4360 - 134ms/epoch - 5ms/step\n",
            "Epoch 6/100\n",
            "27/27 - 0s - loss: 1.4260 - accuracy: 0.5125 - val_loss: 1.3692 - val_accuracy: 0.4597 - 141ms/epoch - 5ms/step\n",
            "Epoch 7/100\n",
            "27/27 - 0s - loss: 1.3823 - accuracy: 0.5279 - val_loss: 1.3454 - val_accuracy: 0.4929 - 146ms/epoch - 5ms/step\n",
            "Epoch 8/100\n",
            "27/27 - 0s - loss: 1.3163 - accuracy: 0.5541 - val_loss: 1.3216 - val_accuracy: 0.5166 - 137ms/epoch - 5ms/step\n",
            "Epoch 9/100\n",
            "27/27 - 0s - loss: 1.2490 - accuracy: 0.5565 - val_loss: 1.2785 - val_accuracy: 0.5450 - 142ms/epoch - 5ms/step\n",
            "Epoch 10/100\n",
            "27/27 - 0s - loss: 1.2176 - accuracy: 0.6052 - val_loss: 1.2537 - val_accuracy: 0.5640 - 154ms/epoch - 6ms/step\n",
            "Epoch 11/100\n",
            "27/27 - 0s - loss: 1.1978 - accuracy: 0.5731 - val_loss: 1.2261 - val_accuracy: 0.5545 - 140ms/epoch - 5ms/step\n",
            "Epoch 12/100\n",
            "27/27 - 0s - loss: 1.1852 - accuracy: 0.5957 - val_loss: 1.1930 - val_accuracy: 0.5735 - 134ms/epoch - 5ms/step\n",
            "Epoch 13/100\n",
            "27/27 - 0s - loss: 1.1812 - accuracy: 0.5826 - val_loss: 1.1314 - val_accuracy: 0.5640 - 147ms/epoch - 5ms/step\n",
            "Epoch 14/100\n",
            "27/27 - 0s - loss: 1.1076 - accuracy: 0.6171 - val_loss: 1.1068 - val_accuracy: 0.5592 - 148ms/epoch - 5ms/step\n",
            "Epoch 15/100\n",
            "27/27 - 0s - loss: 1.1602 - accuracy: 0.5922 - val_loss: 1.0845 - val_accuracy: 0.5972 - 135ms/epoch - 5ms/step\n",
            "Epoch 16/100\n",
            "27/27 - 0s - loss: 1.0781 - accuracy: 0.6468 - val_loss: 1.0361 - val_accuracy: 0.6019 - 141ms/epoch - 5ms/step\n",
            "Epoch 17/100\n",
            "27/27 - 0s - loss: 1.1215 - accuracy: 0.6136 - val_loss: 0.9939 - val_accuracy: 0.6351 - 144ms/epoch - 5ms/step\n",
            "Epoch 18/100\n",
            "27/27 - 0s - loss: 1.0972 - accuracy: 0.6040 - val_loss: 0.9575 - val_accuracy: 0.6351 - 139ms/epoch - 5ms/step\n",
            "Epoch 19/100\n",
            "27/27 - 0s - loss: 1.0587 - accuracy: 0.6302 - val_loss: 0.9350 - val_accuracy: 0.6303 - 138ms/epoch - 5ms/step\n",
            "Epoch 20/100\n",
            "27/27 - 0s - loss: 0.9843 - accuracy: 0.6801 - val_loss: 0.9221 - val_accuracy: 0.6398 - 150ms/epoch - 6ms/step\n",
            "Epoch 21/100\n",
            "27/27 - 0s - loss: 1.0642 - accuracy: 0.6373 - val_loss: 0.9092 - val_accuracy: 0.6445 - 154ms/epoch - 6ms/step\n",
            "Epoch 22/100\n",
            "27/27 - 0s - loss: 1.0419 - accuracy: 0.6492 - val_loss: 0.8821 - val_accuracy: 0.6445 - 136ms/epoch - 5ms/step\n",
            "Epoch 23/100\n",
            "27/27 - 0s - loss: 0.9542 - accuracy: 0.6766 - val_loss: 0.8502 - val_accuracy: 0.6682 - 144ms/epoch - 5ms/step\n",
            "Epoch 24/100\n",
            "27/27 - 0s - loss: 1.0014 - accuracy: 0.6647 - val_loss: 0.8357 - val_accuracy: 0.6872 - 144ms/epoch - 5ms/step\n",
            "Epoch 25/100\n",
            "27/27 - 0s - loss: 0.9839 - accuracy: 0.6671 - val_loss: 0.8396 - val_accuracy: 0.6540 - 131ms/epoch - 5ms/step\n",
            "Epoch 26/100\n",
            "27/27 - 0s - loss: 0.9665 - accuracy: 0.6635 - val_loss: 0.8204 - val_accuracy: 0.6588 - 139ms/epoch - 5ms/step\n",
            "Epoch 27/100\n",
            "27/27 - 0s - loss: 0.9422 - accuracy: 0.6671 - val_loss: 0.8133 - val_accuracy: 0.6445 - 157ms/epoch - 6ms/step\n",
            "Epoch 28/100\n",
            "27/27 - 0s - loss: 0.9554 - accuracy: 0.6813 - val_loss: 0.7995 - val_accuracy: 0.6777 - 149ms/epoch - 6ms/step\n",
            "Epoch 29/100\n",
            "27/27 - 0s - loss: 0.9886 - accuracy: 0.6564 - val_loss: 0.8139 - val_accuracy: 0.6730 - 137ms/epoch - 5ms/step\n",
            "Epoch 30/100\n",
            "27/27 - 0s - loss: 0.9510 - accuracy: 0.6754 - val_loss: 0.8042 - val_accuracy: 0.6588 - 134ms/epoch - 5ms/step\n",
            "Epoch 31/100\n",
            "27/27 - 0s - loss: 0.8868 - accuracy: 0.6908 - val_loss: 0.7805 - val_accuracy: 0.6493 - 136ms/epoch - 5ms/step\n",
            "Epoch 32/100\n",
            "27/27 - 0s - loss: 0.9195 - accuracy: 0.6968 - val_loss: 0.7625 - val_accuracy: 0.6540 - 140ms/epoch - 5ms/step\n",
            "Epoch 33/100\n",
            "27/27 - 0s - loss: 0.7990 - accuracy: 0.7301 - val_loss: 0.7558 - val_accuracy: 0.6777 - 137ms/epoch - 5ms/step\n",
            "Epoch 34/100\n",
            "27/27 - 0s - loss: 0.8546 - accuracy: 0.6885 - val_loss: 0.7343 - val_accuracy: 0.6872 - 157ms/epoch - 6ms/step\n",
            "Epoch 35/100\n",
            "27/27 - 0s - loss: 0.8953 - accuracy: 0.6885 - val_loss: 0.7527 - val_accuracy: 0.6777 - 147ms/epoch - 5ms/step\n",
            "Epoch 36/100\n",
            "27/27 - 0s - loss: 0.8705 - accuracy: 0.7122 - val_loss: 0.7373 - val_accuracy: 0.6919 - 133ms/epoch - 5ms/step\n",
            "Epoch 37/100\n",
            "27/27 - 0s - loss: 0.8832 - accuracy: 0.6861 - val_loss: 0.7178 - val_accuracy: 0.6825 - 149ms/epoch - 6ms/step\n",
            "Epoch 38/100\n",
            "27/27 - 0s - loss: 0.8846 - accuracy: 0.6944 - val_loss: 0.7381 - val_accuracy: 0.6919 - 138ms/epoch - 5ms/step\n",
            "Epoch 39/100\n",
            "27/27 - 0s - loss: 0.8310 - accuracy: 0.7099 - val_loss: 0.7287 - val_accuracy: 0.7014 - 137ms/epoch - 5ms/step\n",
            "Epoch 40/100\n",
            "27/27 - 0s - loss: 0.8289 - accuracy: 0.7182 - val_loss: 0.7201 - val_accuracy: 0.7014 - 139ms/epoch - 5ms/step\n",
            "Epoch 41/100\n",
            "27/27 - 0s - loss: 0.8300 - accuracy: 0.7134 - val_loss: 0.7205 - val_accuracy: 0.7204 - 150ms/epoch - 6ms/step\n",
            "Epoch 42/100\n",
            "27/27 - 0s - loss: 0.8285 - accuracy: 0.7027 - val_loss: 0.7335 - val_accuracy: 0.6872 - 139ms/epoch - 5ms/step\n",
            "Epoch 43/100\n",
            "27/27 - 0s - loss: 0.8188 - accuracy: 0.7241 - val_loss: 0.7240 - val_accuracy: 0.6919 - 137ms/epoch - 5ms/step\n",
            "Epoch 44/100\n",
            "27/27 - 0s - loss: 0.8028 - accuracy: 0.7348 - val_loss: 0.6969 - val_accuracy: 0.7062 - 142ms/epoch - 5ms/step\n",
            "Epoch 45/100\n",
            "27/27 - 0s - loss: 0.8080 - accuracy: 0.7182 - val_loss: 0.6987 - val_accuracy: 0.7062 - 143ms/epoch - 5ms/step\n",
            "Epoch 46/100\n",
            "27/27 - 0s - loss: 0.7958 - accuracy: 0.7277 - val_loss: 0.6832 - val_accuracy: 0.7062 - 135ms/epoch - 5ms/step\n",
            "Epoch 47/100\n",
            "27/27 - 0s - loss: 0.7427 - accuracy: 0.7337 - val_loss: 0.6846 - val_accuracy: 0.7014 - 139ms/epoch - 5ms/step\n",
            "Epoch 48/100\n",
            "27/27 - 0s - loss: 0.7126 - accuracy: 0.7598 - val_loss: 0.6836 - val_accuracy: 0.7014 - 142ms/epoch - 5ms/step\n",
            "Epoch 49/100\n",
            "27/27 - 0s - loss: 0.7670 - accuracy: 0.7372 - val_loss: 0.6659 - val_accuracy: 0.6872 - 149ms/epoch - 6ms/step\n",
            "Epoch 50/100\n",
            "27/27 - 0s - loss: 0.7648 - accuracy: 0.7408 - val_loss: 0.6649 - val_accuracy: 0.7156 - 137ms/epoch - 5ms/step\n",
            "Epoch 51/100\n",
            "27/27 - 0s - loss: 0.7958 - accuracy: 0.7348 - val_loss: 0.6848 - val_accuracy: 0.7014 - 142ms/epoch - 5ms/step\n",
            "Epoch 52/100\n",
            "27/27 - 0s - loss: 0.7271 - accuracy: 0.7598 - val_loss: 0.7000 - val_accuracy: 0.6967 - 134ms/epoch - 5ms/step\n",
            "Epoch 53/100\n",
            "27/27 - 0s - loss: 0.7733 - accuracy: 0.7360 - val_loss: 0.6887 - val_accuracy: 0.6872 - 136ms/epoch - 5ms/step\n",
            "Epoch 54/100\n",
            "27/27 - 0s - loss: 0.7579 - accuracy: 0.7444 - val_loss: 0.7069 - val_accuracy: 0.6825 - 141ms/epoch - 5ms/step\n",
            "Epoch 55/100\n",
            "27/27 - 0s - loss: 0.7818 - accuracy: 0.7396 - val_loss: 0.6777 - val_accuracy: 0.7014 - 136ms/epoch - 5ms/step\n",
            "Epoch 56/100\n",
            "27/27 - 0s - loss: 0.7770 - accuracy: 0.7384 - val_loss: 0.6954 - val_accuracy: 0.7062 - 139ms/epoch - 5ms/step\n",
            "Epoch 57/100\n",
            "27/27 - 0s - loss: 0.7367 - accuracy: 0.7467 - val_loss: 0.6818 - val_accuracy: 0.7014 - 139ms/epoch - 5ms/step\n",
            "Epoch 58/100\n",
            "27/27 - 0s - loss: 0.7120 - accuracy: 0.7562 - val_loss: 0.6745 - val_accuracy: 0.7062 - 138ms/epoch - 5ms/step\n",
            "Epoch 59/100\n",
            "27/27 - 0s - loss: 0.7843 - accuracy: 0.7360 - val_loss: 0.6935 - val_accuracy: 0.7062 - 136ms/epoch - 5ms/step\n",
            "Epoch 60/100\n",
            "27/27 - 0s - loss: 0.7425 - accuracy: 0.7610 - val_loss: 0.6820 - val_accuracy: 0.7062 - 142ms/epoch - 5ms/step\n",
            "Fold 1 - Loss: 0.6649, Accuracy: 71.56%\n",
            "Epoch 1/100\n",
            "27/27 - 2s - loss: 5.0155 - accuracy: 0.3210 - val_loss: 1.3526 - val_accuracy: 0.4123 - 2s/epoch - 66ms/step\n",
            "Epoch 2/100\n",
            "27/27 - 0s - loss: 3.2818 - accuracy: 0.4067 - val_loss: 1.3666 - val_accuracy: 0.5071 - 210ms/epoch - 8ms/step\n",
            "Epoch 3/100\n",
            "27/27 - 0s - loss: 2.3479 - accuracy: 0.4293 - val_loss: 1.3707 - val_accuracy: 0.4313 - 226ms/epoch - 8ms/step\n",
            "Epoch 4/100\n",
            "27/27 - 0s - loss: 1.8359 - accuracy: 0.4602 - val_loss: 1.3727 - val_accuracy: 0.5877 - 233ms/epoch - 9ms/step\n",
            "Epoch 5/100\n",
            "27/27 - 0s - loss: 1.5883 - accuracy: 0.4780 - val_loss: 1.3700 - val_accuracy: 0.5545 - 217ms/epoch - 8ms/step\n",
            "Epoch 6/100\n",
            "27/27 - 0s - loss: 1.4896 - accuracy: 0.5030 - val_loss: 1.3565 - val_accuracy: 0.5829 - 232ms/epoch - 9ms/step\n",
            "Epoch 7/100\n",
            "27/27 - 0s - loss: 1.4742 - accuracy: 0.4899 - val_loss: 1.3436 - val_accuracy: 0.5829 - 250ms/epoch - 9ms/step\n",
            "Epoch 8/100\n",
            "27/27 - 0s - loss: 1.3584 - accuracy: 0.5351 - val_loss: 1.3117 - val_accuracy: 0.6540 - 256ms/epoch - 9ms/step\n",
            "Epoch 9/100\n",
            "27/27 - 0s - loss: 1.3642 - accuracy: 0.5446 - val_loss: 1.2793 - val_accuracy: 0.6256 - 269ms/epoch - 10ms/step\n",
            "Epoch 10/100\n",
            "27/27 - 0s - loss: 1.3265 - accuracy: 0.5696 - val_loss: 1.2240 - val_accuracy: 0.6635 - 177ms/epoch - 7ms/step\n",
            "Epoch 11/100\n",
            "27/27 - 0s - loss: 1.2380 - accuracy: 0.5553 - val_loss: 1.1928 - val_accuracy: 0.6209 - 153ms/epoch - 6ms/step\n",
            "Epoch 12/100\n",
            "27/27 - 0s - loss: 1.3108 - accuracy: 0.5660 - val_loss: 1.1509 - val_accuracy: 0.6777 - 132ms/epoch - 5ms/step\n",
            "Epoch 13/100\n",
            "27/27 - 0s - loss: 1.2724 - accuracy: 0.5743 - val_loss: 1.0929 - val_accuracy: 0.7109 - 146ms/epoch - 5ms/step\n",
            "Epoch 14/100\n",
            "27/27 - 0s - loss: 1.2038 - accuracy: 0.5993 - val_loss: 1.0301 - val_accuracy: 0.7156 - 137ms/epoch - 5ms/step\n",
            "Epoch 15/100\n",
            "27/27 - 0s - loss: 1.1947 - accuracy: 0.5815 - val_loss: 1.0007 - val_accuracy: 0.7204 - 135ms/epoch - 5ms/step\n",
            "Epoch 16/100\n",
            "27/27 - 0s - loss: 1.1541 - accuracy: 0.5981 - val_loss: 0.9112 - val_accuracy: 0.7346 - 146ms/epoch - 5ms/step\n",
            "Epoch 17/100\n",
            "27/27 - 0s - loss: 1.1592 - accuracy: 0.5850 - val_loss: 0.8940 - val_accuracy: 0.7014 - 158ms/epoch - 6ms/step\n",
            "Epoch 18/100\n",
            "27/27 - 0s - loss: 1.1835 - accuracy: 0.5933 - val_loss: 0.8709 - val_accuracy: 0.7156 - 148ms/epoch - 5ms/step\n",
            "Epoch 19/100\n",
            "27/27 - 0s - loss: 1.1307 - accuracy: 0.6136 - val_loss: 0.8294 - val_accuracy: 0.7346 - 147ms/epoch - 5ms/step\n",
            "Epoch 20/100\n",
            "27/27 - 0s - loss: 1.0597 - accuracy: 0.6326 - val_loss: 0.8037 - val_accuracy: 0.7299 - 159ms/epoch - 6ms/step\n",
            "Epoch 21/100\n",
            "27/27 - 0s - loss: 1.0807 - accuracy: 0.6338 - val_loss: 0.7920 - val_accuracy: 0.7536 - 148ms/epoch - 5ms/step\n",
            "Epoch 22/100\n",
            "27/27 - 0s - loss: 1.0451 - accuracy: 0.6326 - val_loss: 0.7505 - val_accuracy: 0.7346 - 143ms/epoch - 5ms/step\n",
            "Epoch 23/100\n",
            "27/27 - 0s - loss: 1.0338 - accuracy: 0.6504 - val_loss: 0.7275 - val_accuracy: 0.7441 - 138ms/epoch - 5ms/step\n",
            "Epoch 24/100\n",
            "27/27 - 0s - loss: 1.0407 - accuracy: 0.6480 - val_loss: 0.7004 - val_accuracy: 0.7536 - 149ms/epoch - 6ms/step\n",
            "Epoch 25/100\n",
            "27/27 - 0s - loss: 1.0517 - accuracy: 0.6350 - val_loss: 0.7185 - val_accuracy: 0.7393 - 136ms/epoch - 5ms/step\n",
            "Epoch 26/100\n",
            "27/27 - 0s - loss: 0.9810 - accuracy: 0.6790 - val_loss: 0.6892 - val_accuracy: 0.7488 - 140ms/epoch - 5ms/step\n",
            "Epoch 27/100\n",
            "27/27 - 0s - loss: 1.0318 - accuracy: 0.6528 - val_loss: 0.6702 - val_accuracy: 0.7393 - 149ms/epoch - 6ms/step\n",
            "Epoch 28/100\n",
            "27/27 - 0s - loss: 0.9940 - accuracy: 0.6587 - val_loss: 0.6732 - val_accuracy: 0.7251 - 136ms/epoch - 5ms/step\n",
            "Epoch 29/100\n",
            "27/27 - 0s - loss: 0.9478 - accuracy: 0.6742 - val_loss: 0.6472 - val_accuracy: 0.7441 - 140ms/epoch - 5ms/step\n",
            "Epoch 30/100\n",
            "27/27 - 0s - loss: 0.9427 - accuracy: 0.6647 - val_loss: 0.6596 - val_accuracy: 0.7299 - 135ms/epoch - 5ms/step\n",
            "Epoch 31/100\n",
            "27/27 - 0s - loss: 0.9377 - accuracy: 0.6623 - val_loss: 0.6510 - val_accuracy: 0.7441 - 147ms/epoch - 5ms/step\n",
            "Epoch 32/100\n",
            "27/27 - 0s - loss: 0.9080 - accuracy: 0.6849 - val_loss: 0.6715 - val_accuracy: 0.7251 - 140ms/epoch - 5ms/step\n",
            "Epoch 33/100\n",
            "27/27 - 0s - loss: 0.9092 - accuracy: 0.6837 - val_loss: 0.6552 - val_accuracy: 0.7536 - 135ms/epoch - 5ms/step\n",
            "Epoch 34/100\n",
            "27/27 - 0s - loss: 0.9022 - accuracy: 0.7015 - val_loss: 0.6436 - val_accuracy: 0.7393 - 146ms/epoch - 5ms/step\n",
            "Epoch 35/100\n",
            "27/27 - 0s - loss: 0.8765 - accuracy: 0.6885 - val_loss: 0.6546 - val_accuracy: 0.7393 - 136ms/epoch - 5ms/step\n",
            "Epoch 36/100\n",
            "27/27 - 0s - loss: 0.8987 - accuracy: 0.6813 - val_loss: 0.6385 - val_accuracy: 0.7488 - 144ms/epoch - 5ms/step\n",
            "Epoch 37/100\n",
            "27/27 - 0s - loss: 0.9043 - accuracy: 0.7146 - val_loss: 0.6390 - val_accuracy: 0.7156 - 138ms/epoch - 5ms/step\n",
            "Epoch 38/100\n",
            "27/27 - 0s - loss: 0.8490 - accuracy: 0.7122 - val_loss: 0.6333 - val_accuracy: 0.7346 - 148ms/epoch - 5ms/step\n",
            "Epoch 39/100\n",
            "27/27 - 0s - loss: 0.8634 - accuracy: 0.7051 - val_loss: 0.6346 - val_accuracy: 0.7441 - 136ms/epoch - 5ms/step\n",
            "Epoch 40/100\n",
            "27/27 - 0s - loss: 0.8854 - accuracy: 0.7063 - val_loss: 0.6455 - val_accuracy: 0.7583 - 134ms/epoch - 5ms/step\n",
            "Epoch 41/100\n",
            "27/27 - 0s - loss: 0.8305 - accuracy: 0.7027 - val_loss: 0.6349 - val_accuracy: 0.7725 - 143ms/epoch - 5ms/step\n",
            "Epoch 42/100\n",
            "27/27 - 0s - loss: 0.8696 - accuracy: 0.7218 - val_loss: 0.6436 - val_accuracy: 0.7441 - 139ms/epoch - 5ms/step\n",
            "Epoch 43/100\n",
            "27/27 - 0s - loss: 0.8970 - accuracy: 0.7039 - val_loss: 0.6008 - val_accuracy: 0.7393 - 141ms/epoch - 5ms/step\n",
            "Epoch 44/100\n",
            "27/27 - 0s - loss: 0.8420 - accuracy: 0.7146 - val_loss: 0.6107 - val_accuracy: 0.7536 - 134ms/epoch - 5ms/step\n",
            "Epoch 45/100\n",
            "27/27 - 0s - loss: 0.8621 - accuracy: 0.7039 - val_loss: 0.5948 - val_accuracy: 0.7488 - 157ms/epoch - 6ms/step\n",
            "Epoch 46/100\n",
            "27/27 - 0s - loss: 0.8171 - accuracy: 0.7229 - val_loss: 0.5846 - val_accuracy: 0.7488 - 144ms/epoch - 5ms/step\n",
            "Epoch 47/100\n",
            "27/27 - 0s - loss: 0.8377 - accuracy: 0.7075 - val_loss: 0.5772 - val_accuracy: 0.7630 - 142ms/epoch - 5ms/step\n",
            "Epoch 48/100\n",
            "27/27 - 0s - loss: 0.7688 - accuracy: 0.7301 - val_loss: 0.5818 - val_accuracy: 0.7678 - 146ms/epoch - 5ms/step\n",
            "Epoch 49/100\n",
            "27/27 - 0s - loss: 0.7664 - accuracy: 0.7598 - val_loss: 0.5905 - val_accuracy: 0.7773 - 136ms/epoch - 5ms/step\n",
            "Epoch 50/100\n",
            "27/27 - 0s - loss: 0.8339 - accuracy: 0.7039 - val_loss: 0.5908 - val_accuracy: 0.7630 - 138ms/epoch - 5ms/step\n",
            "Epoch 51/100\n",
            "27/27 - 0s - loss: 0.8112 - accuracy: 0.7337 - val_loss: 0.5990 - val_accuracy: 0.7441 - 149ms/epoch - 6ms/step\n",
            "Epoch 52/100\n",
            "27/27 - 0s - loss: 0.8622 - accuracy: 0.6992 - val_loss: 0.5925 - val_accuracy: 0.7441 - 143ms/epoch - 5ms/step\n",
            "Epoch 53/100\n",
            "27/27 - 0s - loss: 0.8157 - accuracy: 0.7265 - val_loss: 0.5947 - val_accuracy: 0.7630 - 136ms/epoch - 5ms/step\n",
            "Epoch 54/100\n",
            "27/27 - 0s - loss: 0.7477 - accuracy: 0.7503 - val_loss: 0.5860 - val_accuracy: 0.7583 - 136ms/epoch - 5ms/step\n",
            "Epoch 55/100\n",
            "27/27 - 0s - loss: 0.7686 - accuracy: 0.7420 - val_loss: 0.5834 - val_accuracy: 0.7630 - 146ms/epoch - 5ms/step\n",
            "Epoch 56/100\n",
            "27/27 - 0s - loss: 0.7575 - accuracy: 0.7360 - val_loss: 0.5976 - val_accuracy: 0.7488 - 138ms/epoch - 5ms/step\n",
            "Epoch 57/100\n",
            "27/27 - 0s - loss: 0.7797 - accuracy: 0.7277 - val_loss: 0.5794 - val_accuracy: 0.7725 - 152ms/epoch - 6ms/step\n",
            "Fold 2 - Loss: 0.5772, Accuracy: 76.30%\n",
            "Epoch 1/100\n",
            "27/27 - 2s - loss: 4.9796 - accuracy: 0.3029 - val_loss: 1.3477 - val_accuracy: 0.5000 - 2s/epoch - 65ms/step\n",
            "Epoch 2/100\n",
            "27/27 - 0s - loss: 3.2612 - accuracy: 0.4038 - val_loss: 1.3544 - val_accuracy: 0.5286 - 139ms/epoch - 5ms/step\n",
            "Epoch 3/100\n",
            "27/27 - 0s - loss: 2.2774 - accuracy: 0.4454 - val_loss: 1.3753 - val_accuracy: 0.4095 - 137ms/epoch - 5ms/step\n",
            "Epoch 4/100\n",
            "27/27 - 0s - loss: 1.8426 - accuracy: 0.4834 - val_loss: 1.3725 - val_accuracy: 0.4381 - 139ms/epoch - 5ms/step\n",
            "Epoch 5/100\n",
            "27/27 - 0s - loss: 1.6078 - accuracy: 0.4596 - val_loss: 1.3710 - val_accuracy: 0.4381 - 145ms/epoch - 5ms/step\n",
            "Epoch 6/100\n",
            "27/27 - 0s - loss: 1.4947 - accuracy: 0.4964 - val_loss: 1.3639 - val_accuracy: 0.4667 - 138ms/epoch - 5ms/step\n",
            "Epoch 7/100\n",
            "27/27 - 0s - loss: 1.3807 - accuracy: 0.5273 - val_loss: 1.3340 - val_accuracy: 0.5714 - 268ms/epoch - 10ms/step\n",
            "Epoch 8/100\n",
            "27/27 - 0s - loss: 1.4714 - accuracy: 0.5356 - val_loss: 1.3122 - val_accuracy: 0.6000 - 207ms/epoch - 8ms/step\n",
            "Epoch 9/100\n",
            "27/27 - 0s - loss: 1.2949 - accuracy: 0.5487 - val_loss: 1.2871 - val_accuracy: 0.5857 - 229ms/epoch - 8ms/step\n",
            "Epoch 10/100\n",
            "27/27 - 0s - loss: 1.3111 - accuracy: 0.5534 - val_loss: 1.2500 - val_accuracy: 0.6286 - 235ms/epoch - 9ms/step\n",
            "Epoch 11/100\n",
            "27/27 - 0s - loss: 1.2192 - accuracy: 0.5879 - val_loss: 1.1853 - val_accuracy: 0.6286 - 239ms/epoch - 9ms/step\n",
            "Epoch 12/100\n",
            "27/27 - 0s - loss: 1.2733 - accuracy: 0.5665 - val_loss: 1.1493 - val_accuracy: 0.6524 - 204ms/epoch - 8ms/step\n",
            "Epoch 13/100\n",
            "27/27 - 0s - loss: 1.2325 - accuracy: 0.5879 - val_loss: 1.1279 - val_accuracy: 0.6571 - 246ms/epoch - 9ms/step\n",
            "Epoch 14/100\n",
            "27/27 - 0s - loss: 1.1906 - accuracy: 0.5819 - val_loss: 1.0805 - val_accuracy: 0.6619 - 250ms/epoch - 9ms/step\n",
            "Epoch 15/100\n",
            "27/27 - 0s - loss: 1.1320 - accuracy: 0.6057 - val_loss: 1.0220 - val_accuracy: 0.6667 - 199ms/epoch - 7ms/step\n",
            "Epoch 16/100\n",
            "27/27 - 0s - loss: 1.1117 - accuracy: 0.6200 - val_loss: 0.9739 - val_accuracy: 0.6810 - 261ms/epoch - 10ms/step\n",
            "Epoch 17/100\n",
            "27/27 - 0s - loss: 1.1491 - accuracy: 0.6247 - val_loss: 0.9400 - val_accuracy: 0.6714 - 157ms/epoch - 6ms/step\n",
            "Epoch 18/100\n",
            "27/27 - 0s - loss: 1.1123 - accuracy: 0.6081 - val_loss: 0.9091 - val_accuracy: 0.6667 - 141ms/epoch - 5ms/step\n",
            "Epoch 19/100\n",
            "27/27 - 0s - loss: 1.1045 - accuracy: 0.6283 - val_loss: 0.8979 - val_accuracy: 0.6286 - 135ms/epoch - 5ms/step\n",
            "Epoch 20/100\n",
            "27/27 - 0s - loss: 0.9764 - accuracy: 0.6841 - val_loss: 0.8447 - val_accuracy: 0.6952 - 143ms/epoch - 5ms/step\n",
            "Epoch 21/100\n",
            "27/27 - 0s - loss: 1.1145 - accuracy: 0.6485 - val_loss: 0.8398 - val_accuracy: 0.6714 - 187ms/epoch - 7ms/step\n",
            "Epoch 22/100\n",
            "27/27 - 0s - loss: 0.9979 - accuracy: 0.6603 - val_loss: 0.8002 - val_accuracy: 0.6905 - 135ms/epoch - 5ms/step\n",
            "Epoch 23/100\n",
            "27/27 - 0s - loss: 1.0102 - accuracy: 0.6508 - val_loss: 0.7597 - val_accuracy: 0.7000 - 138ms/epoch - 5ms/step\n",
            "Epoch 24/100\n",
            "27/27 - 0s - loss: 0.9755 - accuracy: 0.6698 - val_loss: 0.7650 - val_accuracy: 0.7095 - 142ms/epoch - 5ms/step\n",
            "Epoch 25/100\n",
            "27/27 - 0s - loss: 1.0093 - accuracy: 0.6639 - val_loss: 0.7515 - val_accuracy: 0.6905 - 139ms/epoch - 5ms/step\n",
            "Epoch 26/100\n",
            "27/27 - 0s - loss: 0.9428 - accuracy: 0.6781 - val_loss: 0.7491 - val_accuracy: 0.6810 - 141ms/epoch - 5ms/step\n",
            "Epoch 27/100\n",
            "27/27 - 0s - loss: 0.9425 - accuracy: 0.6686 - val_loss: 0.7477 - val_accuracy: 0.7048 - 147ms/epoch - 5ms/step\n",
            "Epoch 28/100\n",
            "27/27 - 0s - loss: 0.9643 - accuracy: 0.6734 - val_loss: 0.7314 - val_accuracy: 0.7000 - 149ms/epoch - 6ms/step\n",
            "Epoch 29/100\n",
            "27/27 - 0s - loss: 0.9866 - accuracy: 0.6675 - val_loss: 0.7108 - val_accuracy: 0.7238 - 138ms/epoch - 5ms/step\n",
            "Epoch 30/100\n",
            "27/27 - 0s - loss: 0.9118 - accuracy: 0.7043 - val_loss: 0.6924 - val_accuracy: 0.7333 - 138ms/epoch - 5ms/step\n",
            "Epoch 31/100\n",
            "27/27 - 0s - loss: 0.9286 - accuracy: 0.6971 - val_loss: 0.7102 - val_accuracy: 0.7000 - 132ms/epoch - 5ms/step\n",
            "Epoch 32/100\n",
            "27/27 - 0s - loss: 0.8600 - accuracy: 0.7078 - val_loss: 0.6918 - val_accuracy: 0.6905 - 142ms/epoch - 5ms/step\n",
            "Epoch 33/100\n",
            "27/27 - 0s - loss: 0.8975 - accuracy: 0.7055 - val_loss: 0.6717 - val_accuracy: 0.6857 - 182ms/epoch - 7ms/step\n",
            "Epoch 34/100\n",
            "27/27 - 0s - loss: 0.8797 - accuracy: 0.7019 - val_loss: 0.6822 - val_accuracy: 0.6905 - 133ms/epoch - 5ms/step\n",
            "Epoch 35/100\n",
            "27/27 - 0s - loss: 0.8747 - accuracy: 0.7173 - val_loss: 0.7013 - val_accuracy: 0.6571 - 151ms/epoch - 6ms/step\n",
            "Epoch 36/100\n",
            "27/27 - 0s - loss: 0.8517 - accuracy: 0.7114 - val_loss: 0.6608 - val_accuracy: 0.6952 - 134ms/epoch - 5ms/step\n",
            "Epoch 37/100\n",
            "27/27 - 0s - loss: 0.8835 - accuracy: 0.6983 - val_loss: 0.6680 - val_accuracy: 0.6905 - 135ms/epoch - 5ms/step\n",
            "Epoch 38/100\n",
            "27/27 - 0s - loss: 0.8838 - accuracy: 0.7007 - val_loss: 0.6872 - val_accuracy: 0.7190 - 139ms/epoch - 5ms/step\n",
            "Epoch 39/100\n",
            "27/27 - 0s - loss: 0.8295 - accuracy: 0.7138 - val_loss: 0.6928 - val_accuracy: 0.7095 - 139ms/epoch - 5ms/step\n",
            "Epoch 40/100\n",
            "27/27 - 0s - loss: 0.8467 - accuracy: 0.7185 - val_loss: 0.6749 - val_accuracy: 0.7333 - 143ms/epoch - 5ms/step\n",
            "Epoch 41/100\n",
            "27/27 - 0s - loss: 0.8154 - accuracy: 0.7185 - val_loss: 0.6924 - val_accuracy: 0.7000 - 136ms/epoch - 5ms/step\n",
            "Epoch 42/100\n",
            "27/27 - 0s - loss: 0.8548 - accuracy: 0.7162 - val_loss: 0.6798 - val_accuracy: 0.7190 - 160ms/epoch - 6ms/step\n",
            "Epoch 43/100\n",
            "27/27 - 0s - loss: 0.7754 - accuracy: 0.7173 - val_loss: 0.6542 - val_accuracy: 0.7476 - 149ms/epoch - 6ms/step\n",
            "Epoch 44/100\n",
            "27/27 - 0s - loss: 0.7659 - accuracy: 0.7399 - val_loss: 0.6695 - val_accuracy: 0.7095 - 139ms/epoch - 5ms/step\n",
            "Epoch 45/100\n",
            "27/27 - 0s - loss: 0.7842 - accuracy: 0.7162 - val_loss: 0.6809 - val_accuracy: 0.7238 - 146ms/epoch - 5ms/step\n",
            "Epoch 46/100\n",
            "27/27 - 0s - loss: 0.7796 - accuracy: 0.7268 - val_loss: 0.6681 - val_accuracy: 0.7143 - 144ms/epoch - 5ms/step\n",
            "Epoch 47/100\n",
            "27/27 - 0s - loss: 0.7880 - accuracy: 0.7340 - val_loss: 0.6544 - val_accuracy: 0.7333 - 158ms/epoch - 6ms/step\n",
            "Epoch 48/100\n",
            "27/27 - 0s - loss: 0.7913 - accuracy: 0.7280 - val_loss: 0.6660 - val_accuracy: 0.7238 - 150ms/epoch - 6ms/step\n",
            "Epoch 49/100\n",
            "27/27 - 0s - loss: 0.7322 - accuracy: 0.7494 - val_loss: 0.6424 - val_accuracy: 0.7143 - 140ms/epoch - 5ms/step\n",
            "Epoch 50/100\n",
            "27/27 - 0s - loss: 0.7691 - accuracy: 0.7233 - val_loss: 0.6359 - val_accuracy: 0.7524 - 146ms/epoch - 5ms/step\n",
            "Epoch 51/100\n",
            "27/27 - 0s - loss: 0.7947 - accuracy: 0.7411 - val_loss: 0.6368 - val_accuracy: 0.7429 - 136ms/epoch - 5ms/step\n",
            "Epoch 52/100\n",
            "27/27 - 0s - loss: 0.7599 - accuracy: 0.7150 - val_loss: 0.6515 - val_accuracy: 0.7095 - 135ms/epoch - 5ms/step\n",
            "Epoch 53/100\n",
            "27/27 - 0s - loss: 0.7004 - accuracy: 0.7743 - val_loss: 0.6375 - val_accuracy: 0.7286 - 140ms/epoch - 5ms/step\n",
            "Epoch 54/100\n",
            "27/27 - 0s - loss: 0.7330 - accuracy: 0.7506 - val_loss: 0.6430 - val_accuracy: 0.7381 - 147ms/epoch - 5ms/step\n",
            "Epoch 55/100\n",
            "27/27 - 0s - loss: 0.7161 - accuracy: 0.7553 - val_loss: 0.6344 - val_accuracy: 0.7429 - 158ms/epoch - 6ms/step\n",
            "Epoch 56/100\n",
            "27/27 - 0s - loss: 0.7652 - accuracy: 0.7447 - val_loss: 0.6389 - val_accuracy: 0.7143 - 147ms/epoch - 5ms/step\n",
            "Epoch 57/100\n",
            "27/27 - 0s - loss: 0.6941 - accuracy: 0.7589 - val_loss: 0.6417 - val_accuracy: 0.7381 - 138ms/epoch - 5ms/step\n",
            "Epoch 58/100\n",
            "27/27 - 0s - loss: 0.7117 - accuracy: 0.7542 - val_loss: 0.6467 - val_accuracy: 0.7524 - 136ms/epoch - 5ms/step\n",
            "Epoch 59/100\n",
            "27/27 - 0s - loss: 0.7032 - accuracy: 0.7613 - val_loss: 0.6212 - val_accuracy: 0.7429 - 146ms/epoch - 5ms/step\n",
            "Epoch 60/100\n",
            "27/27 - 0s - loss: 0.7113 - accuracy: 0.7625 - val_loss: 0.6358 - val_accuracy: 0.7476 - 137ms/epoch - 5ms/step\n",
            "Epoch 61/100\n",
            "27/27 - 0s - loss: 0.7410 - accuracy: 0.7518 - val_loss: 0.6244 - val_accuracy: 0.7429 - 149ms/epoch - 6ms/step\n",
            "Epoch 62/100\n",
            "27/27 - 0s - loss: 0.7396 - accuracy: 0.7518 - val_loss: 0.6066 - val_accuracy: 0.7714 - 158ms/epoch - 6ms/step\n",
            "Epoch 63/100\n",
            "27/27 - 0s - loss: 0.7171 - accuracy: 0.7637 - val_loss: 0.6175 - val_accuracy: 0.7571 - 137ms/epoch - 5ms/step\n",
            "Epoch 64/100\n",
            "27/27 - 0s - loss: 0.6594 - accuracy: 0.7684 - val_loss: 0.6114 - val_accuracy: 0.7190 - 146ms/epoch - 5ms/step\n",
            "Epoch 65/100\n",
            "27/27 - 0s - loss: 0.6989 - accuracy: 0.7613 - val_loss: 0.6371 - val_accuracy: 0.7429 - 140ms/epoch - 5ms/step\n",
            "Epoch 66/100\n",
            "27/27 - 0s - loss: 0.7079 - accuracy: 0.7506 - val_loss: 0.6372 - val_accuracy: 0.7524 - 139ms/epoch - 5ms/step\n",
            "Epoch 67/100\n",
            "27/27 - 0s - loss: 0.7316 - accuracy: 0.7577 - val_loss: 0.6439 - val_accuracy: 0.7476 - 144ms/epoch - 5ms/step\n",
            "Epoch 68/100\n",
            "27/27 - 0s - loss: 0.7122 - accuracy: 0.7791 - val_loss: 0.6488 - val_accuracy: 0.7857 - 169ms/epoch - 6ms/step\n",
            "Epoch 69/100\n",
            "27/27 - 0s - loss: 0.6222 - accuracy: 0.7862 - val_loss: 0.6250 - val_accuracy: 0.7857 - 135ms/epoch - 5ms/step\n",
            "Epoch 70/100\n",
            "27/27 - 0s - loss: 0.7324 - accuracy: 0.7518 - val_loss: 0.6384 - val_accuracy: 0.7714 - 147ms/epoch - 5ms/step\n",
            "Epoch 71/100\n",
            "27/27 - 0s - loss: 0.6550 - accuracy: 0.7672 - val_loss: 0.6384 - val_accuracy: 0.7381 - 146ms/epoch - 5ms/step\n",
            "Epoch 72/100\n",
            "27/27 - 0s - loss: 0.6717 - accuracy: 0.7660 - val_loss: 0.6362 - val_accuracy: 0.7619 - 170ms/epoch - 6ms/step\n",
            "Fold 3 - Loss: 0.6066, Accuracy: 77.14%\n",
            "Epoch 1/100\n",
            "27/27 - 2s - loss: 5.3049 - accuracy: 0.2886 - val_loss: 1.3574 - val_accuracy: 0.4714 - 2s/epoch - 60ms/step\n",
            "Epoch 2/100\n",
            "27/27 - 0s - loss: 3.1286 - accuracy: 0.4026 - val_loss: 1.3687 - val_accuracy: 0.4810 - 136ms/epoch - 5ms/step\n",
            "Epoch 3/100\n",
            "27/27 - 0s - loss: 2.1641 - accuracy: 0.4667 - val_loss: 1.3734 - val_accuracy: 0.4857 - 141ms/epoch - 5ms/step\n",
            "Epoch 4/100\n",
            "27/27 - 0s - loss: 1.7481 - accuracy: 0.4786 - val_loss: 1.3799 - val_accuracy: 0.4952 - 137ms/epoch - 5ms/step\n",
            "Epoch 5/100\n",
            "27/27 - 0s - loss: 1.6643 - accuracy: 0.4822 - val_loss: 1.3786 - val_accuracy: 0.4762 - 174ms/epoch - 6ms/step\n",
            "Epoch 6/100\n",
            "27/27 - 0s - loss: 1.5103 - accuracy: 0.4976 - val_loss: 1.3678 - val_accuracy: 0.4857 - 145ms/epoch - 5ms/step\n",
            "Epoch 7/100\n",
            "27/27 - 0s - loss: 1.4378 - accuracy: 0.5202 - val_loss: 1.3537 - val_accuracy: 0.5143 - 146ms/epoch - 5ms/step\n",
            "Epoch 8/100\n",
            "27/27 - 0s - loss: 1.4217 - accuracy: 0.5143 - val_loss: 1.3355 - val_accuracy: 0.5571 - 148ms/epoch - 5ms/step\n",
            "Epoch 9/100\n",
            "27/27 - 0s - loss: 1.4131 - accuracy: 0.5451 - val_loss: 1.3157 - val_accuracy: 0.5429 - 137ms/epoch - 5ms/step\n",
            "Epoch 10/100\n",
            "27/27 - 0s - loss: 1.2903 - accuracy: 0.5558 - val_loss: 1.2894 - val_accuracy: 0.5810 - 135ms/epoch - 5ms/step\n",
            "Epoch 11/100\n",
            "27/27 - 0s - loss: 1.2967 - accuracy: 0.5641 - val_loss: 1.2499 - val_accuracy: 0.6143 - 162ms/epoch - 6ms/step\n",
            "Epoch 12/100\n",
            "27/27 - 0s - loss: 1.1880 - accuracy: 0.5701 - val_loss: 1.1858 - val_accuracy: 0.6095 - 157ms/epoch - 6ms/step\n",
            "Epoch 13/100\n",
            "27/27 - 0s - loss: 1.1774 - accuracy: 0.5819 - val_loss: 1.1332 - val_accuracy: 0.6381 - 149ms/epoch - 6ms/step\n",
            "Epoch 14/100\n",
            "27/27 - 0s - loss: 1.2055 - accuracy: 0.5760 - val_loss: 1.1036 - val_accuracy: 0.6286 - 139ms/epoch - 5ms/step\n",
            "Epoch 15/100\n",
            "27/27 - 0s - loss: 1.1688 - accuracy: 0.6188 - val_loss: 1.0701 - val_accuracy: 0.6333 - 136ms/epoch - 5ms/step\n",
            "Epoch 16/100\n",
            "27/27 - 0s - loss: 1.0832 - accuracy: 0.6152 - val_loss: 0.9926 - val_accuracy: 0.6810 - 141ms/epoch - 5ms/step\n",
            "Epoch 17/100\n",
            "27/27 - 0s - loss: 1.1220 - accuracy: 0.6223 - val_loss: 0.9467 - val_accuracy: 0.6667 - 154ms/epoch - 6ms/step\n",
            "Epoch 18/100\n",
            "27/27 - 0s - loss: 1.1654 - accuracy: 0.6033 - val_loss: 0.9184 - val_accuracy: 0.6667 - 156ms/epoch - 6ms/step\n",
            "Epoch 19/100\n",
            "27/27 - 0s - loss: 1.1222 - accuracy: 0.6081 - val_loss: 0.9111 - val_accuracy: 0.6571 - 152ms/epoch - 6ms/step\n",
            "Epoch 20/100\n",
            "27/27 - 0s - loss: 0.9898 - accuracy: 0.6639 - val_loss: 0.8598 - val_accuracy: 0.6619 - 145ms/epoch - 5ms/step\n",
            "Epoch 21/100\n",
            "27/27 - 0s - loss: 1.0209 - accuracy: 0.6425 - val_loss: 0.8351 - val_accuracy: 0.6619 - 142ms/epoch - 5ms/step\n",
            "Epoch 22/100\n",
            "27/27 - 0s - loss: 0.9655 - accuracy: 0.6627 - val_loss: 0.8130 - val_accuracy: 0.6762 - 138ms/epoch - 5ms/step\n",
            "Epoch 23/100\n",
            "27/27 - 0s - loss: 0.9889 - accuracy: 0.6734 - val_loss: 0.8115 - val_accuracy: 0.6571 - 246ms/epoch - 9ms/step\n",
            "Epoch 24/100\n",
            "27/27 - 0s - loss: 1.0351 - accuracy: 0.6520 - val_loss: 0.8057 - val_accuracy: 0.7048 - 262ms/epoch - 10ms/step\n",
            "Epoch 25/100\n",
            "27/27 - 0s - loss: 0.9631 - accuracy: 0.6758 - val_loss: 0.7884 - val_accuracy: 0.6952 - 195ms/epoch - 7ms/step\n",
            "Epoch 26/100\n",
            "27/27 - 0s - loss: 0.9945 - accuracy: 0.6746 - val_loss: 0.7940 - val_accuracy: 0.6857 - 191ms/epoch - 7ms/step\n",
            "Epoch 27/100\n",
            "27/27 - 0s - loss: 0.9724 - accuracy: 0.6663 - val_loss: 0.7936 - val_accuracy: 0.6952 - 239ms/epoch - 9ms/step\n",
            "Epoch 28/100\n",
            "27/27 - 0s - loss: 0.9610 - accuracy: 0.6496 - val_loss: 0.7733 - val_accuracy: 0.6762 - 251ms/epoch - 9ms/step\n",
            "Epoch 29/100\n",
            "27/27 - 0s - loss: 0.9333 - accuracy: 0.6793 - val_loss: 0.7628 - val_accuracy: 0.6952 - 274ms/epoch - 10ms/step\n",
            "Epoch 30/100\n",
            "27/27 - 0s - loss: 0.8835 - accuracy: 0.6948 - val_loss: 0.7540 - val_accuracy: 0.6952 - 255ms/epoch - 9ms/step\n",
            "Epoch 31/100\n",
            "27/27 - 0s - loss: 0.8752 - accuracy: 0.7043 - val_loss: 0.7434 - val_accuracy: 0.7238 - 207ms/epoch - 8ms/step\n",
            "Epoch 32/100\n",
            "27/27 - 0s - loss: 0.8730 - accuracy: 0.6924 - val_loss: 0.7369 - val_accuracy: 0.7048 - 238ms/epoch - 9ms/step\n",
            "Epoch 33/100\n",
            "27/27 - 0s - loss: 0.8682 - accuracy: 0.6971 - val_loss: 0.7355 - val_accuracy: 0.7143 - 176ms/epoch - 7ms/step\n",
            "Epoch 34/100\n",
            "27/27 - 0s - loss: 0.9126 - accuracy: 0.7114 - val_loss: 0.7212 - val_accuracy: 0.7190 - 140ms/epoch - 5ms/step\n",
            "Epoch 35/100\n",
            "27/27 - 0s - loss: 0.8979 - accuracy: 0.6924 - val_loss: 0.7212 - val_accuracy: 0.7143 - 139ms/epoch - 5ms/step\n",
            "Epoch 36/100\n",
            "27/27 - 0s - loss: 0.9050 - accuracy: 0.6936 - val_loss: 0.7116 - val_accuracy: 0.7333 - 138ms/epoch - 5ms/step\n",
            "Epoch 37/100\n",
            "27/27 - 0s - loss: 0.8748 - accuracy: 0.6912 - val_loss: 0.7027 - val_accuracy: 0.7143 - 155ms/epoch - 6ms/step\n",
            "Epoch 38/100\n",
            "27/27 - 0s - loss: 0.7987 - accuracy: 0.7352 - val_loss: 0.7033 - val_accuracy: 0.7048 - 151ms/epoch - 6ms/step\n",
            "Epoch 39/100\n",
            "27/27 - 0s - loss: 0.8169 - accuracy: 0.7162 - val_loss: 0.6852 - val_accuracy: 0.7429 - 136ms/epoch - 5ms/step\n",
            "Epoch 40/100\n",
            "27/27 - 0s - loss: 0.8790 - accuracy: 0.6983 - val_loss: 0.6898 - val_accuracy: 0.7381 - 149ms/epoch - 6ms/step\n",
            "Epoch 41/100\n",
            "27/27 - 0s - loss: 0.8544 - accuracy: 0.7114 - val_loss: 0.7054 - val_accuracy: 0.7286 - 141ms/epoch - 5ms/step\n",
            "Epoch 42/100\n",
            "27/27 - 0s - loss: 0.8453 - accuracy: 0.7233 - val_loss: 0.7027 - val_accuracy: 0.7286 - 140ms/epoch - 5ms/step\n",
            "Epoch 43/100\n",
            "27/27 - 0s - loss: 0.8274 - accuracy: 0.7090 - val_loss: 0.6886 - val_accuracy: 0.7429 - 132ms/epoch - 5ms/step\n",
            "Epoch 44/100\n",
            "27/27 - 0s - loss: 0.8003 - accuracy: 0.7209 - val_loss: 0.6851 - val_accuracy: 0.7333 - 135ms/epoch - 5ms/step\n",
            "Epoch 45/100\n",
            "27/27 - 0s - loss: 0.7662 - accuracy: 0.7411 - val_loss: 0.6961 - val_accuracy: 0.7381 - 155ms/epoch - 6ms/step\n",
            "Epoch 46/100\n",
            "27/27 - 0s - loss: 0.8131 - accuracy: 0.7363 - val_loss: 0.6973 - val_accuracy: 0.7476 - 131ms/epoch - 5ms/step\n",
            "Epoch 47/100\n",
            "27/27 - 0s - loss: 0.7498 - accuracy: 0.7601 - val_loss: 0.6830 - val_accuracy: 0.7381 - 155ms/epoch - 6ms/step\n",
            "Epoch 48/100\n",
            "27/27 - 0s - loss: 0.7400 - accuracy: 0.7435 - val_loss: 0.6661 - val_accuracy: 0.7524 - 140ms/epoch - 5ms/step\n",
            "Epoch 49/100\n",
            "27/27 - 0s - loss: 0.8210 - accuracy: 0.7162 - val_loss: 0.6729 - val_accuracy: 0.7333 - 183ms/epoch - 7ms/step\n",
            "Epoch 50/100\n",
            "27/27 - 0s - loss: 0.8365 - accuracy: 0.7126 - val_loss: 0.6949 - val_accuracy: 0.7143 - 134ms/epoch - 5ms/step\n",
            "Epoch 51/100\n",
            "27/27 - 0s - loss: 0.7634 - accuracy: 0.7257 - val_loss: 0.6891 - val_accuracy: 0.7095 - 184ms/epoch - 7ms/step\n",
            "Epoch 52/100\n",
            "27/27 - 0s - loss: 0.7873 - accuracy: 0.7304 - val_loss: 0.6810 - val_accuracy: 0.7571 - 144ms/epoch - 5ms/step\n",
            "Epoch 53/100\n",
            "27/27 - 0s - loss: 0.7586 - accuracy: 0.7423 - val_loss: 0.6579 - val_accuracy: 0.7571 - 189ms/epoch - 7ms/step\n",
            "Epoch 54/100\n",
            "27/27 - 0s - loss: 0.7823 - accuracy: 0.7387 - val_loss: 0.6777 - val_accuracy: 0.7238 - 140ms/epoch - 5ms/step\n",
            "Epoch 55/100\n",
            "27/27 - 0s - loss: 0.7697 - accuracy: 0.7423 - val_loss: 0.6766 - val_accuracy: 0.7476 - 133ms/epoch - 5ms/step\n",
            "Epoch 56/100\n",
            "27/27 - 0s - loss: 0.7567 - accuracy: 0.7482 - val_loss: 0.6943 - val_accuracy: 0.7190 - 137ms/epoch - 5ms/step\n",
            "Epoch 57/100\n",
            "27/27 - 0s - loss: 0.7556 - accuracy: 0.7637 - val_loss: 0.6867 - val_accuracy: 0.7381 - 134ms/epoch - 5ms/step\n",
            "Epoch 58/100\n",
            "27/27 - 0s - loss: 0.7510 - accuracy: 0.7506 - val_loss: 0.6967 - val_accuracy: 0.7190 - 154ms/epoch - 6ms/step\n",
            "Epoch 59/100\n",
            "27/27 - 0s - loss: 0.7316 - accuracy: 0.7458 - val_loss: 0.6996 - val_accuracy: 0.7143 - 133ms/epoch - 5ms/step\n",
            "Epoch 60/100\n",
            "27/27 - 0s - loss: 0.6853 - accuracy: 0.7684 - val_loss: 0.6911 - val_accuracy: 0.7095 - 152ms/epoch - 6ms/step\n",
            "Epoch 61/100\n",
            "27/27 - 0s - loss: 0.7105 - accuracy: 0.7553 - val_loss: 0.6770 - val_accuracy: 0.7333 - 149ms/epoch - 6ms/step\n",
            "Epoch 62/100\n",
            "27/27 - 0s - loss: 0.6797 - accuracy: 0.7613 - val_loss: 0.6750 - val_accuracy: 0.7476 - 138ms/epoch - 5ms/step\n",
            "Epoch 63/100\n",
            "27/27 - 0s - loss: 0.6882 - accuracy: 0.7672 - val_loss: 0.6703 - val_accuracy: 0.7381 - 139ms/epoch - 5ms/step\n",
            "Fold 4 - Loss: 0.6579, Accuracy: 75.71%\n",
            "Epoch 1/100\n",
            "27/27 - 2s - loss: 4.8042 - accuracy: 0.3195 - val_loss: 1.3810 - val_accuracy: 0.4048 - 2s/epoch - 60ms/step\n",
            "Epoch 2/100\n",
            "27/27 - 0s - loss: 2.9196 - accuracy: 0.4074 - val_loss: 1.3569 - val_accuracy: 0.4952 - 144ms/epoch - 5ms/step\n",
            "Epoch 3/100\n",
            "27/27 - 0s - loss: 2.2899 - accuracy: 0.4133 - val_loss: 1.3690 - val_accuracy: 0.4905 - 139ms/epoch - 5ms/step\n",
            "Epoch 4/100\n",
            "27/27 - 0s - loss: 1.8314 - accuracy: 0.4727 - val_loss: 1.3738 - val_accuracy: 0.5286 - 140ms/epoch - 5ms/step\n",
            "Epoch 5/100\n",
            "27/27 - 0s - loss: 1.5945 - accuracy: 0.4786 - val_loss: 1.3701 - val_accuracy: 0.4857 - 140ms/epoch - 5ms/step\n",
            "Epoch 6/100\n",
            "27/27 - 0s - loss: 1.5540 - accuracy: 0.4822 - val_loss: 1.3604 - val_accuracy: 0.5143 - 155ms/epoch - 6ms/step\n",
            "Epoch 7/100\n",
            "27/27 - 0s - loss: 1.5067 - accuracy: 0.4893 - val_loss: 1.3497 - val_accuracy: 0.5619 - 149ms/epoch - 6ms/step\n",
            "Epoch 8/100\n",
            "27/27 - 0s - loss: 1.3844 - accuracy: 0.5523 - val_loss: 1.3175 - val_accuracy: 0.6048 - 142ms/epoch - 5ms/step\n",
            "Epoch 9/100\n",
            "27/27 - 0s - loss: 1.3068 - accuracy: 0.5641 - val_loss: 1.2619 - val_accuracy: 0.6476 - 145ms/epoch - 5ms/step\n",
            "Epoch 10/100\n",
            "27/27 - 0s - loss: 1.2969 - accuracy: 0.5701 - val_loss: 1.2165 - val_accuracy: 0.6476 - 157ms/epoch - 6ms/step\n",
            "Epoch 11/100\n",
            "27/27 - 0s - loss: 1.2451 - accuracy: 0.5701 - val_loss: 1.1899 - val_accuracy: 0.6476 - 142ms/epoch - 5ms/step\n",
            "Epoch 12/100\n",
            "27/27 - 0s - loss: 1.2286 - accuracy: 0.5938 - val_loss: 1.1482 - val_accuracy: 0.6429 - 139ms/epoch - 5ms/step\n",
            "Epoch 13/100\n",
            "27/27 - 0s - loss: 1.2175 - accuracy: 0.5772 - val_loss: 1.0730 - val_accuracy: 0.6381 - 152ms/epoch - 6ms/step\n",
            "Epoch 14/100\n",
            "27/27 - 0s - loss: 1.1900 - accuracy: 0.6128 - val_loss: 1.0341 - val_accuracy: 0.6714 - 143ms/epoch - 5ms/step\n",
            "Epoch 15/100\n",
            "27/27 - 0s - loss: 1.0784 - accuracy: 0.6449 - val_loss: 0.9789 - val_accuracy: 0.6714 - 143ms/epoch - 5ms/step\n",
            "Epoch 16/100\n",
            "27/27 - 0s - loss: 1.2126 - accuracy: 0.5998 - val_loss: 0.9408 - val_accuracy: 0.6810 - 147ms/epoch - 5ms/step\n",
            "Epoch 17/100\n",
            "27/27 - 0s - loss: 1.0690 - accuracy: 0.6283 - val_loss: 0.9213 - val_accuracy: 0.6810 - 147ms/epoch - 5ms/step\n",
            "Epoch 18/100\n",
            "27/27 - 0s - loss: 1.1162 - accuracy: 0.6283 - val_loss: 0.8841 - val_accuracy: 0.7000 - 135ms/epoch - 5ms/step\n",
            "Epoch 19/100\n",
            "27/27 - 0s - loss: 1.0842 - accuracy: 0.6247 - val_loss: 0.8522 - val_accuracy: 0.7000 - 141ms/epoch - 5ms/step\n",
            "Epoch 20/100\n",
            "27/27 - 0s - loss: 1.0667 - accuracy: 0.6176 - val_loss: 0.8207 - val_accuracy: 0.6762 - 156ms/epoch - 6ms/step\n",
            "Epoch 21/100\n",
            "27/27 - 0s - loss: 1.0231 - accuracy: 0.6627 - val_loss: 0.7944 - val_accuracy: 0.6857 - 140ms/epoch - 5ms/step\n",
            "Epoch 22/100\n",
            "27/27 - 0s - loss: 1.1097 - accuracy: 0.6532 - val_loss: 0.7575 - val_accuracy: 0.7238 - 143ms/epoch - 5ms/step\n",
            "Epoch 23/100\n",
            "27/27 - 0s - loss: 1.0187 - accuracy: 0.6603 - val_loss: 0.7583 - val_accuracy: 0.7048 - 153ms/epoch - 6ms/step\n",
            "Epoch 24/100\n",
            "27/27 - 0s - loss: 0.9702 - accuracy: 0.6912 - val_loss: 0.7420 - val_accuracy: 0.6714 - 150ms/epoch - 6ms/step\n",
            "Epoch 25/100\n",
            "27/27 - 0s - loss: 0.9970 - accuracy: 0.6627 - val_loss: 0.7265 - val_accuracy: 0.6667 - 231ms/epoch - 9ms/step\n",
            "Epoch 26/100\n",
            "27/27 - 0s - loss: 1.0037 - accuracy: 0.6793 - val_loss: 0.7336 - val_accuracy: 0.6905 - 244ms/epoch - 9ms/step\n",
            "Epoch 27/100\n",
            "27/27 - 0s - loss: 0.9681 - accuracy: 0.6900 - val_loss: 0.7198 - val_accuracy: 0.6857 - 192ms/epoch - 7ms/step\n",
            "Epoch 28/100\n",
            "27/27 - 0s - loss: 0.9617 - accuracy: 0.6758 - val_loss: 0.7167 - val_accuracy: 0.6905 - 233ms/epoch - 9ms/step\n",
            "Epoch 29/100\n",
            "27/27 - 0s - loss: 0.9159 - accuracy: 0.6841 - val_loss: 0.6950 - val_accuracy: 0.7286 - 224ms/epoch - 8ms/step\n",
            "Epoch 30/100\n",
            "27/27 - 0s - loss: 0.8711 - accuracy: 0.7185 - val_loss: 0.6917 - val_accuracy: 0.7238 - 224ms/epoch - 8ms/step\n",
            "Epoch 31/100\n",
            "27/27 - 0s - loss: 0.9355 - accuracy: 0.7019 - val_loss: 0.6969 - val_accuracy: 0.7381 - 200ms/epoch - 7ms/step\n",
            "Epoch 32/100\n",
            "27/27 - 0s - loss: 0.8571 - accuracy: 0.7162 - val_loss: 0.6981 - val_accuracy: 0.7190 - 224ms/epoch - 8ms/step\n",
            "Epoch 33/100\n",
            "27/27 - 0s - loss: 0.9385 - accuracy: 0.6805 - val_loss: 0.6812 - val_accuracy: 0.7381 - 255ms/epoch - 9ms/step\n",
            "Epoch 34/100\n",
            "27/27 - 0s - loss: 0.9646 - accuracy: 0.6948 - val_loss: 0.6915 - val_accuracy: 0.7286 - 243ms/epoch - 9ms/step\n",
            "Epoch 35/100\n",
            "27/27 - 0s - loss: 0.8930 - accuracy: 0.6960 - val_loss: 0.6698 - val_accuracy: 0.7333 - 147ms/epoch - 5ms/step\n",
            "Epoch 36/100\n",
            "27/27 - 0s - loss: 0.8777 - accuracy: 0.7114 - val_loss: 0.6876 - val_accuracy: 0.7286 - 131ms/epoch - 5ms/step\n",
            "Epoch 37/100\n",
            "27/27 - 0s - loss: 0.8354 - accuracy: 0.7150 - val_loss: 0.6841 - val_accuracy: 0.7143 - 135ms/epoch - 5ms/step\n",
            "Epoch 38/100\n",
            "27/27 - 0s - loss: 0.8782 - accuracy: 0.6912 - val_loss: 0.6660 - val_accuracy: 0.7524 - 157ms/epoch - 6ms/step\n",
            "Epoch 39/100\n",
            "27/27 - 0s - loss: 0.8057 - accuracy: 0.7292 - val_loss: 0.6563 - val_accuracy: 0.7381 - 145ms/epoch - 5ms/step\n",
            "Epoch 40/100\n",
            "27/27 - 0s - loss: 0.8529 - accuracy: 0.7221 - val_loss: 0.6522 - val_accuracy: 0.7381 - 144ms/epoch - 5ms/step\n",
            "Epoch 41/100\n",
            "27/27 - 0s - loss: 0.8373 - accuracy: 0.7233 - val_loss: 0.6566 - val_accuracy: 0.7286 - 138ms/epoch - 5ms/step\n",
            "Epoch 42/100\n",
            "27/27 - 0s - loss: 0.9015 - accuracy: 0.6995 - val_loss: 0.6841 - val_accuracy: 0.7381 - 146ms/epoch - 5ms/step\n",
            "Epoch 43/100\n",
            "27/27 - 0s - loss: 0.7881 - accuracy: 0.7304 - val_loss: 0.6725 - val_accuracy: 0.7381 - 135ms/epoch - 5ms/step\n",
            "Epoch 44/100\n",
            "27/27 - 0s - loss: 0.8386 - accuracy: 0.7185 - val_loss: 0.6605 - val_accuracy: 0.7429 - 136ms/epoch - 5ms/step\n",
            "Epoch 45/100\n",
            "27/27 - 0s - loss: 0.8043 - accuracy: 0.7292 - val_loss: 0.6512 - val_accuracy: 0.7286 - 151ms/epoch - 6ms/step\n",
            "Epoch 46/100\n",
            "27/27 - 0s - loss: 0.7787 - accuracy: 0.7411 - val_loss: 0.6426 - val_accuracy: 0.7000 - 137ms/epoch - 5ms/step\n",
            "Epoch 47/100\n",
            "27/27 - 0s - loss: 0.7938 - accuracy: 0.7506 - val_loss: 0.6512 - val_accuracy: 0.7381 - 133ms/epoch - 5ms/step\n",
            "Epoch 48/100\n",
            "27/27 - 0s - loss: 0.7944 - accuracy: 0.7375 - val_loss: 0.6372 - val_accuracy: 0.7762 - 146ms/epoch - 5ms/step\n",
            "Epoch 49/100\n",
            "27/27 - 0s - loss: 0.7440 - accuracy: 0.7411 - val_loss: 0.6545 - val_accuracy: 0.7524 - 142ms/epoch - 5ms/step\n",
            "Epoch 50/100\n",
            "27/27 - 0s - loss: 0.7212 - accuracy: 0.7375 - val_loss: 0.6411 - val_accuracy: 0.7476 - 134ms/epoch - 5ms/step\n",
            "Epoch 51/100\n",
            "27/27 - 0s - loss: 0.7370 - accuracy: 0.7743 - val_loss: 0.6209 - val_accuracy: 0.7857 - 146ms/epoch - 5ms/step\n",
            "Epoch 52/100\n",
            "27/27 - 0s - loss: 0.7616 - accuracy: 0.7292 - val_loss: 0.6078 - val_accuracy: 0.7810 - 144ms/epoch - 5ms/step\n",
            "Epoch 53/100\n",
            "27/27 - 0s - loss: 0.7636 - accuracy: 0.7470 - val_loss: 0.6129 - val_accuracy: 0.7667 - 133ms/epoch - 5ms/step\n",
            "Epoch 54/100\n",
            "27/27 - 0s - loss: 0.7622 - accuracy: 0.7363 - val_loss: 0.6053 - val_accuracy: 0.7762 - 143ms/epoch - 5ms/step\n",
            "Epoch 55/100\n",
            "27/27 - 0s - loss: 0.8021 - accuracy: 0.7328 - val_loss: 0.6197 - val_accuracy: 0.7476 - 134ms/epoch - 5ms/step\n",
            "Epoch 56/100\n",
            "27/27 - 0s - loss: 0.7241 - accuracy: 0.7601 - val_loss: 0.6176 - val_accuracy: 0.7714 - 141ms/epoch - 5ms/step\n",
            "Epoch 57/100\n",
            "27/27 - 0s - loss: 0.7468 - accuracy: 0.7565 - val_loss: 0.6258 - val_accuracy: 0.7571 - 135ms/epoch - 5ms/step\n",
            "Epoch 58/100\n",
            "27/27 - 0s - loss: 0.7775 - accuracy: 0.7352 - val_loss: 0.6175 - val_accuracy: 0.7619 - 149ms/epoch - 6ms/step\n",
            "Epoch 59/100\n",
            "27/27 - 0s - loss: 0.7016 - accuracy: 0.7684 - val_loss: 0.6150 - val_accuracy: 0.7619 - 146ms/epoch - 5ms/step\n",
            "Epoch 60/100\n",
            "27/27 - 0s - loss: 0.6616 - accuracy: 0.7838 - val_loss: 0.6034 - val_accuracy: 0.7810 - 145ms/epoch - 5ms/step\n",
            "Epoch 61/100\n",
            "27/27 - 0s - loss: 0.7124 - accuracy: 0.7601 - val_loss: 0.6284 - val_accuracy: 0.7476 - 158ms/epoch - 6ms/step\n",
            "Epoch 62/100\n",
            "27/27 - 0s - loss: 0.7086 - accuracy: 0.7625 - val_loss: 0.6094 - val_accuracy: 0.7714 - 147ms/epoch - 5ms/step\n",
            "Epoch 63/100\n",
            "27/27 - 0s - loss: 0.6842 - accuracy: 0.7720 - val_loss: 0.6226 - val_accuracy: 0.7667 - 164ms/epoch - 6ms/step\n",
            "Epoch 64/100\n",
            "27/27 - 0s - loss: 0.7574 - accuracy: 0.7577 - val_loss: 0.6166 - val_accuracy: 0.7429 - 138ms/epoch - 5ms/step\n",
            "Epoch 65/100\n",
            "27/27 - 0s - loss: 0.8051 - accuracy: 0.7470 - val_loss: 0.6126 - val_accuracy: 0.7619 - 153ms/epoch - 6ms/step\n",
            "Epoch 66/100\n",
            "27/27 - 0s - loss: 0.6973 - accuracy: 0.7672 - val_loss: 0.6014 - val_accuracy: 0.7762 - 140ms/epoch - 5ms/step\n",
            "Epoch 67/100\n",
            "27/27 - 0s - loss: 0.6962 - accuracy: 0.7696 - val_loss: 0.6085 - val_accuracy: 0.7524 - 141ms/epoch - 5ms/step\n",
            "Epoch 68/100\n",
            "27/27 - 0s - loss: 0.7029 - accuracy: 0.7708 - val_loss: 0.6215 - val_accuracy: 0.7619 - 136ms/epoch - 5ms/step\n",
            "Epoch 69/100\n",
            "27/27 - 0s - loss: 0.7056 - accuracy: 0.7743 - val_loss: 0.6104 - val_accuracy: 0.7619 - 150ms/epoch - 6ms/step\n",
            "Epoch 70/100\n",
            "27/27 - 0s - loss: 0.7108 - accuracy: 0.7577 - val_loss: 0.6435 - val_accuracy: 0.7524 - 144ms/epoch - 5ms/step\n",
            "Epoch 71/100\n",
            "27/27 - 0s - loss: 0.6917 - accuracy: 0.7684 - val_loss: 0.6281 - val_accuracy: 0.7524 - 145ms/epoch - 5ms/step\n",
            "Epoch 72/100\n",
            "27/27 - 0s - loss: 0.7108 - accuracy: 0.7708 - val_loss: 0.6211 - val_accuracy: 0.7571 - 145ms/epoch - 5ms/step\n",
            "Epoch 73/100\n",
            "27/27 - 0s - loss: 0.7394 - accuracy: 0.7577 - val_loss: 0.6271 - val_accuracy: 0.7524 - 139ms/epoch - 5ms/step\n",
            "Epoch 74/100\n",
            "27/27 - 0s - loss: 0.6851 - accuracy: 0.7708 - val_loss: 0.6074 - val_accuracy: 0.7714 - 140ms/epoch - 5ms/step\n",
            "Epoch 75/100\n",
            "27/27 - 0s - loss: 0.6558 - accuracy: 0.7945 - val_loss: 0.6211 - val_accuracy: 0.7429 - 136ms/epoch - 5ms/step\n",
            "Epoch 76/100\n",
            "27/27 - 0s - loss: 0.6329 - accuracy: 0.8112 - val_loss: 0.6079 - val_accuracy: 0.7476 - 156ms/epoch - 6ms/step\n",
            "Fold 5 - Loss: 0.6014, Accuracy: 77.62%\n",
            "Average Loss across all folds: 0.6216\n",
            "Average Accuracy across all folds: 75.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s00FcKEG1ZMx"
      },
      "source": [
        "## Save K fold model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZeDY-UQ1eVR",
        "outputId": "efe6ba03-d33b-49d5-e44d-cd189e2a8dfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model for fold 6 at /content/drive/MyDrive/ModelOutputs/cnn_model_fold_6.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "# Inside your loop after training the model\n",
        "model_path = f'/content/drive/MyDrive/ModelOutputs/cnn_model_fold_{fold_no}.h5'\n",
        "model.save(model_path)\n",
        "print(f'Saved model for fold {fold_no} at {model_path}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhzJpZQ-zC5G"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Read test numpy file**"
      ],
      "metadata": {
        "id": "WIENdFNcIl5V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/blocks-testing.zip -d /content/"
      ],
      "metadata": {
        "id": "3FV8YtbF8_P3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcdac90a-a63b-48b4-e109-14550dcd1aed"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/blocks-testing.zip\n",
            "  inflating: /content/blocks/subject_2_block_2_testing_50_CSP_Features.npz  \n",
            "  inflating: /content/blocks/subject_8_block_1_testing_50_CSP_Features.npz  \n",
            "  inflating: /content/blocks/subject_9_block_1_testing_50_CSP_Features.npz  \n",
            "  inflating: /content/blocks/subject_7_block_2_testing_50_CSP_Features.npz  \n",
            "  inflating: /content/blocks/subject_8_block_3_testing_50_CSP_Features.npz  \n",
            "  inflating: /content/blocks/subject_7_block_1_testing_50_CSP_Features.npz  \n",
            "  inflating: /content/blocks/subject_2_block_1_testing_50_CSP_Features.npz  \n",
            "  inflating: /content/blocks/subject_2_block_3_testing_50_CSP_Features.npz  \n",
            "  inflating: /content/blocks/subject_7_block_3_testing_50_CSP_Features.npz  \n",
            "  inflating: /content/blocks/subject_9_block_3_testing_50_CSP_Features.npz  \n",
            "  inflating: /content/blocks/subject_8_block_2_testing_50_CSP_Features.npz  \n",
            "  inflating: /content/blocks/subject_9_block_2_testing_50_CSP_Features.npz  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Load the .npz file\n",
        "new_data = np.load('/content/blocks/subject_9_block_2_testing_50_CSP_Features.npz')\n",
        "# List all arrays in the .npz file\n",
        "print(new_data.files)\n",
        "\n",
        "# Access and print each array\n",
        "\n",
        "for array_name in new_data.files:\n",
        "    print(array_name)\n",
        "    print(new_data[array_name])\n",
        "\n",
        "new_data['features'].shape\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FHPDvVVIqJm",
        "outputId": "437a3b51-e87c-4c93-c659-30922a9610dd"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['features', 'labels']\n",
            "features\n",
            "[[ 0.48875392 -0.89840649 -0.48407872 ... -0.16432919 -0.17102698\n",
            "   0.11350036]\n",
            " [ 1.13073145 -1.44320754 -0.21878282 ... -0.23054738 -0.40618273\n",
            "  -0.37264044]\n",
            " [ 0.26438056 -0.41610298 -0.79332694 ... -0.31707106 -0.22925015\n",
            "  -0.56608851]\n",
            " ...\n",
            " [-0.31972822 -0.48843425 -0.40839506 ...  0.02057862 -0.52276422\n",
            "  -0.585623  ]\n",
            " [-1.05596389 -1.27911481 -1.25993033 ...  0.34087616 -0.60916793\n",
            "  -0.91123695]\n",
            " [-1.00416009 -1.18843323  2.34372977 ...  0.34415601 -0.69779873\n",
            "  -0.61550921]]\n",
            "labels\n",
            "[[356714      1      1      1]\n",
            " [363523      1      1      1]\n",
            " [369991      0      1      1]\n",
            " ...\n",
            " [934739      1      1      2]\n",
            " [948238      1      1      2]\n",
            " [954877      2      1      2]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(840, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "vK02uH4YtXa4"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.distplot(new_data['features'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "LsyTVASuta_t",
        "outputId": "bd85c6d7-b1ae-48da-ebee-3a82d5f2e6a5"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-35-3a0bd1c95662>:1: UserWarning: \n",
            "\n",
            "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
            "\n",
            "Please adapt your code to use either `displot` (a figure-level function with\n",
            "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "\n",
            "For a guide to updating your code to use the new functions, please see\n",
            "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
            "\n",
            "  sns.distplot(new_data['features'])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: ylabel='Density'>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocess and clean numpy file**"
      ],
      "metadata": {
        "id": "0TLn4ahPJHHn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "labels= new_data['labels']\n",
        "labels= labels[:, 1]\n",
        "labels.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlW3MyArJOT_",
        "outputId": "3b24049b-61ea-4824-eca2-8e4dbe3eef5c"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(840,)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "unique, frequency = np.unique(labels,\n",
        "                              return_counts = True)\n",
        "\n",
        "# convert both into one numpy array\n",
        "count = np.asarray((unique, frequency ))\n",
        "\n",
        "print(\"The values and their frequency are:\\n\",\n",
        "     count)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuH9PevizAOe",
        "outputId": "02b6a916-6712-4007-f96e-c7cec9caac79"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The values and their frequency are:\n",
            " [[  0   1   2   3]\n",
            " [210 210 210 210]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "import joblib\n",
        "\n",
        "\n",
        "\n",
        "# Load the .npz file\n",
        "\n",
        "# Assuming 'Feature' and 'Label' are keys in the npz file\n",
        "features = new_data['features']\n",
        "\n",
        "# Function to clean feature strings\n",
        "def clean_feature_string(feature_str):\n",
        "    if isinstance(feature_str, str):\n",
        "        cleaned = feature_str.strip('[]').replace(' ', ',').replace('\\n', '')\n",
        "        return cleaned.split(',') if cleaned else []\n",
        "    return feature_str  # If it's already a list or array, return as is\n",
        "\n",
        "# Convert the feature strings to lists of floats\n",
        "cleaned_features = []\n",
        "for feature in features:\n",
        "    cleaned_feature = clean_feature_string(feature)\n",
        "    if len(cleaned_feature) == 0:\n",
        "        cleaned_feature = [0.0] * 10  # Handle empty features by filling with placeholder\n",
        "    cleaned_features.append([float(i) for i in cleaned_feature])\n",
        "\n",
        "# Convert cleaned_features to a numpy array\n",
        "X_new = np.array(cleaned_features)\n",
        "y_new= labels\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "QPZbwcgUJLNk"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import yeojohnson\n",
        "\n",
        "\n",
        "transformed_data = {}\n",
        "\n",
        "\n",
        "    # Apply Yeo-Johnson transformation\n",
        "transformed_array, lambda_value = yeojohnson(X_new.flatten())\n",
        "\n",
        "    # Reshape transformed array to original shape\n",
        "transformed_array = transformed_array.reshape(X_new.shape)\n",
        "\n",
        "    # Standardize the transformed data\n",
        "mean = np.mean(transformed_array)\n",
        "std = np.std(transformed_array)\n",
        "standardized_array = (transformed_array - mean) / std\n",
        "\n",
        "    # Store the standardized data\n",
        "transformed_data_new = standardized_array\n",
        "\n",
        "    # Plot histogram of standardized data\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.hist(standardized_array.flatten(), bins=50, alpha=0.6, density=True)\n",
        "plt.title(f'Histogram of Standardized Yeo-Johnson Transformed Data for X')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Density')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Optionally, save the transformed data back to a new npz file\n",
        "'''\n",
        "scaled_X_new= scaler.transform(X_new)\n"
      ],
      "metadata": {
        "id": "wZ3fBdW9Uf_G"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "\n",
        "sns.distplot(scaled_X_new)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "xTpHp-62uQGF",
        "outputId": "75962d65-762a-400a-aaa7-c41f5f493d0d"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-40-f8d1aec07339>:4: UserWarning: \n",
            "\n",
            "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
            "\n",
            "Please adapt your code to use either `displot` (a figure-level function with\n",
            "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "\n",
            "For a guide to updating your code to use the new functions, please see\n",
            "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
            "\n",
            "  sns.distplot(scaled_X_new)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: ylabel='Density'>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y_new.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXXioGLWwlGh",
        "outputId": "f5ca884e-b260-4a38-b10e-8fd26e8f9f8a"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(840,)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "r1nbiHhfCqjh"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Reshape the data for the model if necessary (e.g., CNN input)\n",
        "X_new_transformed = scaled_X_new.reshape(scaled_X_new.shape[0], scaled_X_new.shape[1], 1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_new_transformed.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zXO4TonGLSh",
        "outputId": "93820167-250c-445b-8320-e42f5318331a"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(840, 50, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9_cpcRpAEb-",
        "outputId": "87426767-8f09-4a6d-8dcd-7b3365d40365"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded from /content/drive/MyDrive/MyOutput/tested_3_cnn_model\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "model_path ='/content/drive/MyDrive/MyOutput/tested_3_cnn_model'\n",
        "from keras import models\n",
        "model = models.load_model(model_path)\n",
        "print(f\"Model loaded from {model_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Assuming model and data are already loaded and prepared\n",
        "from sklearn.metrics import accuracy_score\n",
        "predictions = model.predict(X_new_transformed)\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "accuracy = accuracy_score(y_new, predicted_classes)\n",
        "print(\"Overall accuracy on test data: {:.2%}\".format(accuracy))\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "report = classification_report(y_new, predicted_classes)\n",
        "print('CNN Model Classification Report:')\n",
        "print(report)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFgt03TJLLgb",
        "outputId": "a66c3b09-ee66-4435-b4b3-86efb67be4b3"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27/27 [==============================] - 0s 2ms/step\n",
            "Overall accuracy on test data: 27.86%\n",
            "CNN Model Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.25      0.20      0.22       210\n",
            "           1       0.23      0.33      0.28       210\n",
            "           2       0.26      0.21      0.23       210\n",
            "           3       0.37      0.38      0.38       210\n",
            "\n",
            "    accuracy                           0.28       840\n",
            "   macro avg       0.28      0.28      0.28       840\n",
            "weighted avg       0.28      0.28      0.28       840\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qIY_fSkWaGut"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mhyEUawQwrC"
      },
      "source": [
        "## Normalize the shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqui1dZqQye4",
        "outputId": "ba6f7be0-3d67-4fd1-f8be-a9800a40591a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN Model Accuracy--> Testing: 23.00%\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "CNN Model Classification Report on Extracted Features:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.38      0.32      0.35        50\n",
            "           1       0.27      0.30      0.29        50\n",
            "           2       0.18      0.20      0.19        50\n",
            "           3       0.11      0.10      0.10        50\n",
            "\n",
            "    accuracy                           0.23       200\n",
            "   macro avg       0.23      0.23      0.23       200\n",
            "weighted avg       0.23      0.23      0.23       200\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Evaluate the model on the extracted features\n",
        "try:\n",
        "    loss, accuracy = model.evaluate(csp_features_reshaped, labels_categorical, verbose=0)\n",
        "    print(f'CNN Model Accuracy--> Testing: {accuracy:.2%}')\n",
        "except ValueError as e:\n",
        "    print(f\"Error during model evaluation: {e}\")\n",
        "\n",
        "# Make predictions\n",
        "try:\n",
        "    y_pred = model.predict(csp_features_reshaped)\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "    labels_classes = np.argmax(labels_categorical, axis=1)\n",
        "\n",
        "    # Generate a classification report\n",
        "    report = classification_report(labels_classes, y_pred_classes)\n",
        "    print('CNN Model Classification Report on Extracted Features:')\n",
        "    print(report)\n",
        "except ValueError as e:\n",
        "    print(f\"Error during model prediction: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANGx4lxW79Ii",
        "outputId": "a467c929-5016-440e-a06a-f29dd3b9dd3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading /content/drive/MyDrive/FYPD_Dataset/derivatives/sub-02/ses-02/sub-02_ses-02_eeg-epo.fif ...\n",
            "Isotrak not found\n",
            "    Found the data of interest:\n",
            "        t =    -500.00 ...    4000.00 ms\n",
            "        0 CTF compensation matrices available\n",
            "Not setting metadata\n",
            "200 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Shape of new data (X_new): (200, 147584, 1)\n",
            "Shape of new labels (y_new): (200, 4)\n",
            "Expected input shape by the model: (None, 50, 1)\n"
          ]
        }
      ],
      "source": [
        "import mne\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def extract_features_from_file(file_path):\n",
        "    # Load the EEG data from the FIF file\n",
        "    epochs = mne.read_epochs(file_path, preload=True)\n",
        "    X = epochs.get_data()  # Get the data in (n_epochs, n_channels, n_times) format\n",
        "    y = epochs.events[:, -1]  # Get the event labels\n",
        "\n",
        "    # Reshape the data to be suitable for Conv1D\n",
        "    X = X.reshape(X.shape[0], X.shape[1] * X.shape[2])\n",
        "\n",
        "    # Normalize the features\n",
        "    scaler = StandardScaler()\n",
        "    X = scaler.fit_transform(X)\n",
        "\n",
        "    # Adjust labels to be zero-based\n",
        "    label_mapping = {label: index for index, label in enumerate(np.unique(y))}\n",
        "    y = np.array([label_mapping[label] for label in y])\n",
        "\n",
        "    # Reshape the features for Conv1D input\n",
        "    X_reshaped = X.reshape(X.shape[0], X.shape[1], 1)\n",
        "\n",
        "    # Convert labels to categorical\n",
        "    num_classes = len(np.unique(y))\n",
        "    y_categorical = tf.keras.utils.to_categorical(y, num_classes=num_classes)\n",
        "\n",
        "    return X_reshaped, y_categorical, num_classes\n",
        "\n",
        "# Load the EEG data\n",
        "file_path = '/content/drive/MyDrive/FYPD_Dataset/derivatives/sub-02/ses-02/sub-02_ses-02_eeg-epo.fif'  # Path to the uploaded EEG file\n",
        "X_new, y_new, num_classes = extract_features_from_file(file_path)\n",
        "\n",
        "print(f\"Shape of new data (X_new): {X_new.shape}\")\n",
        "print(f\"Shape of new labels (y_new): {y_new.shape}\")\n",
        "\n",
        "# Print model input shape\n",
        "print(f\"Expected input shape by the model: {model.input_shape}\")\n",
        "\n",
        "# # Load the EEG data\n",
        "# X_new, y_new, num_classes = load_eeg_data(file_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwK2si4QAXfE"
      },
      "source": [
        "## Evaluate the Model on the New Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYsefdPMAZQM",
        "outputId": "7809a5ec-90b9-48f5-e8a4-a08238f37699"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during model evaluation: in user code:\n",
            "\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2066, in test_function  *\n",
            "        return step_function(self, iterator)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2049, in step_function  **\n",
            "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2037, in run_step  **\n",
            "        outputs = model.test_step(data)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1917, in test_step\n",
            "        y_pred = self(x, training=False)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n",
            "        raise e.with_traceback(filtered_tb) from None\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n",
            "        raise ValueError(\n",
            "\n",
            "    ValueError: Input 0 of layer \"sequential_3\" is incompatible with the layer: expected shape=(None, 50, 1), found shape=(None, 147584, 1)\n",
            "\n",
            "Error during model prediction: in user code:\n",
            "\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2440, in predict_function  *\n",
            "        return step_function(self, iterator)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2425, in step_function  **\n",
            "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2413, in run_step  **\n",
            "        outputs = model.predict_step(data)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2381, in predict_step\n",
            "        return self(x, training=False)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n",
            "        raise e.with_traceback(filtered_tb) from None\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n",
            "        raise ValueError(\n",
            "\n",
            "    ValueError: Input 0 of layer \"sequential_3\" is incompatible with the layer: expected shape=(None, 50, 1), found shape=(None, 147584, 1)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Evaluate the model on the new data\n",
        "try:\n",
        "    loss, accuracy = model.evaluate(X_new, y_new, verbose=0)\n",
        "    print(f'CNN Model Accuracy on New Data: {accuracy:.2%}')\n",
        "except ValueError as e:\n",
        "    print(f\"Error during model evaluation: {e}\")\n",
        "\n",
        "# Make predictions\n",
        "try:\n",
        "    y_pred = model.predict(X_new)\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "    y_new_classes = np.argmax(y_new, axis=1)\n",
        "\n",
        "    # Generate a classification report\n",
        "    report = classification_report(y_new_classes, y_pred_classes)\n",
        "    print('CNN Model Classification Report on New Data:')\n",
        "    print(report)\n",
        "except ValueError as e:\n",
        "    print(f\"Error during model prediction: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0B9nIR6zLri"
      },
      "source": [
        "# New extra"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsVADlHX1RuV",
        "outputId": "a981d22b-82c9-42c2-8b3f-49ac5b1d106a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "111/111 [==============================] - 2s 8ms/step - loss: 176.4421 - mae: 9.7518 - val_loss: 40.1687 - val_mae: 5.2627\n",
            "Epoch 2/20\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 25.7334 - mae: 3.8410 - val_loss: 12.4803 - val_mae: 2.7096\n",
            "Epoch 3/20\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 9.4238 - mae: 2.3544 - val_loss: 6.2638 - val_mae: 1.9274\n",
            "Epoch 4/20\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 4.2071 - mae: 1.5911 - val_loss: 2.7501 - val_mae: 1.3267\n",
            "Epoch 5/20\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 2.3970 - mae: 1.2467 - val_loss: 1.9288 - val_mae: 1.1388\n",
            "Epoch 6/20\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 1.8316 - mae: 1.1152 - val_loss: 1.5683 - val_mae: 1.0495\n",
            "Epoch 7/20\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 1.6542 - mae: 1.0748 - val_loss: 1.4872 - val_mae: 1.0258\n",
            "Epoch 8/20\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 1.5169 - mae: 1.0362 - val_loss: 1.4301 - val_mae: 1.0192\n",
            "Epoch 9/20\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 1.5119 - mae: 1.0339 - val_loss: 1.3866 - val_mae: 0.9963\n",
            "Epoch 10/20\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 1.4113 - mae: 1.0044 - val_loss: 1.3176 - val_mae: 0.9856\n",
            "Epoch 11/20\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 1.4206 - mae: 1.0057 - val_loss: 1.3670 - val_mae: 0.9909\n",
            "Epoch 12/20\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 1.2983 - mae: 0.9669 - val_loss: 1.2868 - val_mae: 0.9680\n",
            "Epoch 13/20\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 1.4259 - mae: 0.9999 - val_loss: 1.2657 - val_mae: 0.9625\n",
            "Epoch 14/20\n",
            "111/111 [==============================] - 1s 11ms/step - loss: 1.2612 - mae: 0.9561 - val_loss: 1.2985 - val_mae: 0.9662\n",
            "Epoch 15/20\n",
            "111/111 [==============================] - 1s 12ms/step - loss: 1.2237 - mae: 0.9395 - val_loss: 1.4654 - val_mae: 1.0078\n",
            "Epoch 16/20\n",
            "111/111 [==============================] - 1s 11ms/step - loss: 1.2830 - mae: 0.9529 - val_loss: 1.2656 - val_mae: 0.9516\n",
            "Epoch 17/20\n",
            "111/111 [==============================] - 1s 11ms/step - loss: 1.2461 - mae: 0.9396 - val_loss: 1.2259 - val_mae: 0.9369\n",
            "Epoch 18/20\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 1.2166 - mae: 0.9312 - val_loss: 1.4917 - val_mae: 1.0115\n",
            "Epoch 19/20\n",
            "111/111 [==============================] - 1s 6ms/step - loss: 1.2326 - mae: 0.9325 - val_loss: 1.2247 - val_mae: 0.9301\n",
            "Epoch 20/20\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 1.1453 - mae: 0.9017 - val_loss: 1.1947 - val_mae: 0.9223\n",
            "28/28 [==============================] - 0s 2ms/step\n",
            "CNN Model Accuracy: 23.32%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.00      0.00      0.00         0\n",
            "           0       0.41      0.07      0.13       240\n",
            "           1       0.29      0.50      0.37       214\n",
            "           2       0.30      0.54      0.38       227\n",
            "           3       0.00      0.00      0.00         0\n",
            "           4       0.00      0.00      0.00       207\n",
            "\n",
            "    accuracy                           0.28       888\n",
            "   macro avg       0.17      0.19      0.15       888\n",
            "weighted avg       0.26      0.28      0.22       888\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_csv('/content/drive/MyDrive/extracted_features.csv')\n",
        "\n",
        "# Correct the parsing of feature arrays by ensuring proper formatting\n",
        "def clean_feature_string(feature_string):\n",
        "    cleaned_string = re.sub(r'\\s+', ',', feature_string.strip())\n",
        "    cleaned_string = cleaned_string.replace('[,', '[').replace(',,', ',').replace(',]', ']')\n",
        "    return np.array(eval(cleaned_string))\n",
        "\n",
        "data['Feature'] = data['Feature'].apply(clean_feature_string)\n",
        "\n",
        "# Stack features into a 2D array and labels into a 1D array\n",
        "features = np.stack(data['Feature'].values)\n",
        "labels = data['Label'].values\n",
        "\n",
        "# Normalize the features\n",
        "scaler = StandardScaler()\n",
        "features_normalized = scaler.fit_transform(features)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(features_normalized, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Reshape the data to fit the model input\n",
        "X_train_cnn = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test_cnn = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "# Define the CNN model\n",
        "model = Sequential([\n",
        "    Conv1D(32, kernel_size=3, activation='relu', input_shape=(50, 1)),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Conv1D(64, kernel_size=3, activation='relu'),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Flatten(),\n",
        "    Dense(100, activation='relu'),\n",
        "    Dense(1, activation='linear')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train_cnn, y_train, epochs=20, batch_size=32, validation_data=(X_test_cnn, y_test))\n",
        "\n",
        "# Predict on the test data\n",
        "y_test_pred = model.predict(X_test_cnn)\n",
        "\n",
        "# Convert the continuous output to discrete bins\n",
        "num_bins = 5  # Number of bins can be adjusted\n",
        "bins = np.linspace(min(labels), max(labels), num_bins)\n",
        "y_test_binned = np.digitize(y_test, bins) - 1\n",
        "y_test_pred_binned = np.digitize(y_test_pred, bins) - 1\n",
        "\n",
        "# Calculate the classification report\n",
        "report = classification_report(y_test_binned, y_test_pred_binned)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = np.mean(y_test_binned == y_test_pred_binned)\n",
        "\n",
        "print(f\"CNN Model Accuracy: {accuracy * 100:.2f}%\")\n",
        "print(report)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69iQ9NICzOto",
        "outputId": "b9753bcf-63f1-4b3c-ae6d-b9088b47799e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "111/111 [==============================] - 4s 13ms/step - loss: 175.7122 - mae: 9.6878 - val_loss: 35.9343 - val_mae: 4.8169\n",
            "Epoch 2/20\n",
            "111/111 [==============================] - 1s 11ms/step - loss: 26.5478 - mae: 3.9539 - val_loss: 12.8748 - val_mae: 2.8419\n",
            "Epoch 3/20\n",
            "111/111 [==============================] - 1s 11ms/step - loss: 10.0083 - mae: 2.4371 - val_loss: 5.9592 - val_mae: 1.9236\n",
            "Epoch 4/20\n",
            "111/111 [==============================] - 1s 11ms/step - loss: 4.5641 - mae: 1.6779 - val_loss: 2.8791 - val_mae: 1.3650\n",
            "Epoch 5/20\n",
            "111/111 [==============================] - 1s 11ms/step - loss: 2.3866 - mae: 1.2546 - val_loss: 2.2113 - val_mae: 1.2204\n",
            "Epoch 6/20\n",
            "111/111 [==============================] - 2s 20ms/step - loss: 1.8034 - mae: 1.1048 - val_loss: 1.5750 - val_mae: 1.0529\n",
            "Epoch 7/20\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 1.6314 - mae: 1.0653 - val_loss: 1.4604 - val_mae: 1.0232\n",
            "Epoch 8/20\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 1.5168 - mae: 1.0322 - val_loss: 1.7220 - val_mae: 1.0951\n",
            "Epoch 9/20\n",
            "111/111 [==============================] - 1s 13ms/step - loss: 1.5403 - mae: 1.0420 - val_loss: 1.4340 - val_mae: 1.0148\n",
            "Epoch 10/20\n",
            "111/111 [==============================] - 1s 10ms/step - loss: 1.4810 - mae: 1.0254 - val_loss: 1.9822 - val_mae: 1.1525\n",
            "Epoch 11/20\n",
            "111/111 [==============================] - 1s 11ms/step - loss: 1.4082 - mae: 1.0039 - val_loss: 1.3328 - val_mae: 0.9884\n",
            "Epoch 12/20\n",
            "111/111 [==============================] - 1s 11ms/step - loss: 1.3705 - mae: 0.9979 - val_loss: 1.3310 - val_mae: 0.9872\n",
            "Epoch 13/20\n",
            "111/111 [==============================] - 1s 10ms/step - loss: 1.3818 - mae: 0.9951 - val_loss: 1.5155 - val_mae: 1.0311\n",
            "Epoch 14/20\n",
            "111/111 [==============================] - 1s 10ms/step - loss: 1.3872 - mae: 0.9972 - val_loss: 1.3259 - val_mae: 0.9818\n",
            "Epoch 15/20\n",
            "111/111 [==============================] - 1s 12ms/step - loss: 1.3247 - mae: 0.9762 - val_loss: 1.2513 - val_mae: 0.9643\n",
            "Epoch 16/20\n",
            "111/111 [==============================] - 1s 11ms/step - loss: 1.2890 - mae: 0.9660 - val_loss: 1.3076 - val_mae: 0.9748\n",
            "Epoch 17/20\n",
            "111/111 [==============================] - 1s 12ms/step - loss: 1.3377 - mae: 0.9780 - val_loss: 1.8805 - val_mae: 1.1224\n",
            "Epoch 18/20\n",
            "111/111 [==============================] - 2s 15ms/step - loss: 1.3365 - mae: 0.9770 - val_loss: 1.2575 - val_mae: 0.9597\n",
            "Epoch 19/20\n",
            "111/111 [==============================] - 2s 15ms/step - loss: 1.2916 - mae: 0.9591 - val_loss: 1.3571 - val_mae: 0.9819\n",
            "Epoch 20/20\n",
            "111/111 [==============================] - 1s 13ms/step - loss: 1.3001 - mae: 0.9644 - val_loss: 1.2133 - val_mae: 0.9456\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1.2133 - mae: 0.9456\n",
            "Test Loss: 1.2132960557937622\n",
            "Test MAE: 0.9456014037132263\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_csv('/content/drive/MyDrive/extracted_features.csv')\n",
        "\n",
        "# Correct the parsing of feature arrays by ensuring proper formatting\n",
        "def clean_feature_string(feature_string):\n",
        "    cleaned_string = re.sub(r'\\s+', ',', feature_string.strip())\n",
        "    cleaned_string = cleaned_string.replace('[,', '[').replace(',,', ',').replace(',]', ']')\n",
        "    return np.array(eval(cleaned_string))\n",
        "\n",
        "data['Feature'] = data['Feature'].apply(clean_feature_string)\n",
        "\n",
        "# Stack features into a 2D array and labels into a 1D array\n",
        "features = np.stack(data['Feature'].values)\n",
        "labels = data['Label'].values\n",
        "\n",
        "# Normalize the features\n",
        "scaler = StandardScaler()\n",
        "features_normalized = scaler.fit_transform(features)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(features_normalized, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Reshape the data to fit the model input\n",
        "X_train_cnn = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test_cnn = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "# Define the CNN model\n",
        "model = Sequential([\n",
        "    Conv1D(32, kernel_size=3, activation='relu', input_shape=(50, 1)),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Conv1D(64, kernel_size=3, activation='relu'),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Flatten(),\n",
        "    Dense(100, activation='relu'),\n",
        "    Dense(1, activation='linear')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train_cnn, y_train, epochs=20, batch_size=32, validation_data=(X_test_cnn, y_test))\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test_loss, test_mae = model.evaluate(X_test_cnn, y_test)\n",
        "\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test MAE:\", test_mae)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RaJptFA-Ls0"
      },
      "source": [
        "## Extra proprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QmIB7uxm3-RT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "# Function to clean feature strings\n",
        "def clean_feature_string(feature_str):\n",
        "    if pd.isnull(feature_str) or not feature_str.strip() or feature_str == '[]':\n",
        "        return []\n",
        "    return feature_str.strip('[]').replace(' ', ',').replace('\\n', '')\n",
        "\n",
        "# Apply the cleaning function\n",
        "data['Feature'] = data['Feature'].apply(clean_feature_string)\n",
        "\n",
        "# Handle empty features by filling them with a placeholder (e.g., [0.0])\n",
        "data['Feature'] = data['Feature'].apply(lambda x: [0.0] * 10 if not x else x)\n",
        "\n",
        "# Convert the 'Feature' column from string to list of floats\n",
        "data['Feature'] = data['Feature'].apply(lambda x: [float(i) for i in x.split(',') if i])\n",
        "\n",
        "# Separate features and labels\n",
        "X = np.array(data['Feature'].tolist())\n",
        "y = data['Label'].values\n",
        "\n",
        "# Normalize the features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Adjust labels to be zero-based\n",
        "label_mapping = {label: index for index, label in enumerate(np.unique(y))}\n",
        "y = np.array([label_mapping[label] for label in y])\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert labels to categorical\n",
        "num_classes = len(np.unique(y))\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes=num_classes)\n",
        "\n",
        "print(\"First few rows of scaled features:\")\n",
        "print(X[:5])\n",
        "print(\"First few labels (one-hot encoded):\")\n",
        "print(y_train[:5])\n",
        "\n",
        "print(\"Data cleaning and preparation complete.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrxFm8tV8myO",
        "outputId": "fd5c2000-72e8-4e96-f98f-bd2b7e32c6f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                             Feature  Label\n",
            "0  [-1.10592278e+00  1.26334574e-01  1.80643464e-...     34\n",
            "1  [-1.59924221 -0.40243337 -0.31018183  0.224682...     31\n",
            "2  [-1.82392118  0.0323609  -0.63397414 -0.298704...     33\n",
            "3  [-2.02208584 -0.86507523  0.47099887  0.28327 ...     34\n",
            "4  [-2.23357765 -0.59810067 -0.53470548 -0.338026...     33\n",
            "[34 31 33 32]\n",
            "Label\n",
            "34    50\n",
            "31    50\n",
            "33    50\n",
            "32    50\n",
            "Name: count, dtype: int64\n",
            "First few rows of scaled features:\n",
            "[[ 3.77990529e-01  1.54757842e+00  1.28896999e+00  1.60678322e+00\n",
            "   7.11408168e-01  1.23456748e+00  4.28556105e+00  1.44633189e+00\n",
            "   8.59980444e-01  6.23869014e-02  1.25626824e-01  2.33765317e+00\n",
            "   6.43307720e-01  1.23008561e+00  1.58786304e+00  1.28558636e+00\n",
            "   2.43454844e+00  7.40956414e-01  3.00150890e+00  1.72194286e+00\n",
            "   5.22425818e-01  3.84711981e+00  6.15001906e-01  5.06155898e+00\n",
            "   4.31361047e+00  2.73515148e+00 -1.26054528e+00  7.57351592e-02\n",
            "   3.06943753e+00  1.99457431e+00  2.26970806e+00  1.65134862e+00\n",
            "   8.57201502e-01  1.02579848e+00 -2.05505973e-01 -4.94043147e-01\n",
            "   3.88056081e-01  1.64535454e+00  1.34768707e-01  2.47550741e+00\n",
            "  -1.59856922e-01 -2.18740127e-01  2.63285222e+00  1.62427749e+00\n",
            "   6.78541340e-01  3.24146345e+00  2.18367295e+00  2.15322964e+00\n",
            "  -3.94555551e-01  5.79991222e-01]\n",
            " [-2.00065379e-01  5.10109710e-01  4.54456005e-01  1.45508460e+00\n",
            "  -2.61695907e-01  5.39757139e-01  1.12795603e+00  7.71392326e-01\n",
            "   2.62090344e+00  1.49735260e+00  1.08153656e+00  6.85761269e-01\n",
            "   2.92400917e-01  9.65027080e-01  1.49757493e+00 -1.55552313e-01\n",
            "   8.95238937e-01  1.13164697e+00  5.39118559e-01  3.87824946e-01\n",
            "   2.62176751e-01  4.88748978e-01 -5.23934603e-01  1.48970767e+00\n",
            "   6.16265101e-01  7.30383864e-01  9.99656634e-01  1.80776218e+00\n",
            "   2.11915443e+00  1.48560636e-01  3.38947790e-01  2.02121798e+00\n",
            "   2.08721278e+00  1.12352058e+00  8.12983738e-01  7.56179069e-01\n",
            "   1.14430498e+00  5.81608077e-01  2.17717341e+00  2.48319747e+00\n",
            "   4.38089224e-01  1.06258369e+00 -7.88007290e-02  2.60686253e+00\n",
            "   2.17326188e+00  4.53434480e-01  6.65325092e-01  2.32836569e+00\n",
            "   1.11734252e+00  9.01300238e-01]\n",
            " [-4.63337001e-01  1.36319745e+00 -9.60641384e-02  2.98162202e-01\n",
            "  -5.67815242e-01  3.73872082e-02  1.92693881e-02 -5.04165259e-01\n",
            "  -6.09543160e-01  2.92794988e-01  1.19656435e+00  3.47236281e+00\n",
            "   3.38375841e+00  4.59658202e-01  2.76399960e-02  3.00292857e+00\n",
            "  -5.97790497e-01  4.07129831e-01  3.76409006e+00  1.49279745e-01\n",
            "   7.96619081e-01  8.52746733e-01  3.05546937e+00  5.70572142e-01\n",
            "   1.09095091e+00  5.35332916e-01  1.88762073e+00  3.45979137e-01\n",
            "   1.40041357e+00  1.39542783e+00  8.56494876e-01  1.03249388e+00\n",
            "  -5.97918541e-01 -5.51995772e-01 -2.73683574e-01  1.76794321e-01\n",
            "   1.64645075e+00  2.28487238e-01  3.54751919e-01  4.43793751e+00\n",
            "   1.72923291e+00  1.75660927e+00  1.55330947e-01  1.85670223e-01\n",
            "   1.08708594e+00  6.16983090e-01 -6.78798902e-04  3.20022018e-02\n",
            "   9.12656043e-01  1.35072584e+00]\n",
            " [-6.95540003e-01 -3.97616370e-01  1.78263984e+00  1.58458862e+00\n",
            "   9.02203895e-01  6.00724121e-02  2.99334832e+00  1.92269148e+00\n",
            "   1.61633043e+00  1.11650830e+00  3.61441010e-01  2.04847614e+00\n",
            "   6.66854692e-01  1.41781929e+00  3.85131740e-01  1.35399683e+00\n",
            "   1.77368889e+00  1.08889278e+00  3.77293691e+00  2.55773239e+00\n",
            "   1.14607856e+00  3.27258246e+00  5.02208129e-01  1.65962895e+00\n",
            "   2.97628531e+00  2.57236784e+00 -3.05331259e-02  5.14200019e-01\n",
            "   5.19824409e+00  1.42682955e+00  5.31087888e-01  1.11694016e+00\n",
            "   7.78241370e-01  2.02140110e-01  1.33929213e+00  8.02916067e-02\n",
            "   1.06815169e+00  3.35412367e+00 -2.74399469e-02  3.55895954e+00\n",
            "   8.26256882e-01  2.44402154e+00  1.66095038e+00  3.65143781e-01\n",
            "   8.79584878e-02  3.66273423e+00  9.99970513e-01  1.25034403e+00\n",
            "  -3.27876954e-01 -3.06783163e-02]\n",
            " [-9.43359332e-01  1.26200846e-01  7.27150304e-02  2.11242262e-01\n",
            "   8.93364025e-01 -4.72241834e-02  1.78220109e+00  1.42280838e-01\n",
            "   3.01501280e-01  1.59927703e+00  1.73432884e+00  1.63760463e+00\n",
            "   3.90868004e+00  2.27980407e+00  8.49334492e-01  1.14075637e+00\n",
            "  -9.58357990e-01  3.41521631e-01  3.86198895e+00 -4.39797032e-01\n",
            "   1.91616722e-01 -1.69896642e-01  1.20946660e+00  4.61110041e-01\n",
            "  -4.31488319e-02  5.35138180e-01  2.35235693e+00  1.26115602e+00\n",
            "   1.87907788e+00  1.18693200e+00  7.76113527e-01  7.91657923e-01\n",
            "  -4.49322800e-01  2.93106512e-01 -5.15198764e-01  1.65894814e+00\n",
            "   1.41940931e+00 -2.86428334e-01  7.92825283e-01  1.77976236e+00\n",
            "   2.57048266e-01  2.26227409e+00  1.38599570e+00 -6.80790542e-01\n",
            "   1.83816503e+00  1.61295146e+00  3.85140571e-01 -1.41332570e-01\n",
            "   2.06277749e+00  8.40220490e-01]]\n",
            "First few labels (one-hot encoded):\n",
            "[[0. 0. 1. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]]\n",
            "Data cleaning and preparation complete.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file\n",
        "text_csv_file_name = '/content/drive/MyDrive/MyOutput/tested_extracted_features2.csv'\n",
        "data = pd.read_csv(text_csv_file_name)\n",
        "\n",
        "\n",
        "# Display the first few rows of the dataframe to inspect the data\n",
        "print(data.head())\n",
        "print(data['Label'].unique())\n",
        "print(data['Label'].value_counts())\n",
        "\n",
        "\n",
        "# Function to clean feature strings\n",
        "def clean_feature_string(feature_str):\n",
        "    if pd.isnull(feature_str) or not feature_str.strip() or feature_str == '[]':\n",
        "        return []\n",
        "    return feature_str.strip('[]').replace(' ', ',').replace('\\n', '')\n",
        "\n",
        "# Apply the cleaning function\n",
        "data['Feature'] = data['Feature'].apply(clean_feature_string)\n",
        "\n",
        "# Handle empty features by filling them with a placeholder (e.g., [0.0])\n",
        "data['Feature'] = data['Feature'].apply(lambda x: [0.0] * 10 if not x else x)\n",
        "\n",
        "# Convert the 'Feature' column from string to list of floats\n",
        "data['Feature'] = data['Feature'].apply(lambda x: [float(i) for i in x.split(',') if i])\n",
        "\n",
        "# Separate features and labels\n",
        "X = np.array(data['Feature'].tolist())\n",
        "y = data['Label'].values\n",
        "\n",
        "# Normalize the features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Adjust labels to be zero-based (assuming the same label mapping as training)\n",
        "label_mapping = {label: index for index, label in enumerate(np.unique(y_new))}\n",
        "y_new = np.array([label_mapping[label] for label in y_new])\n",
        "\n",
        "# Convert labels to categorical\n",
        "num_classes = len(np.unique(y_new))\n",
        "y_new_categorical = tf.keras.utils.to_categorical(y_new, num_classes=num_classes)\n",
        "\n",
        "# Reshape the data to fit the model input\n",
        "X_new_reshaped = X_new.reshape(X_new.shape[0], X_new.shape[1], 1)\n",
        "\n",
        "print(\"First few rows of scaled features:\")\n",
        "print(X[:5])\n",
        "print(\"First few labels (one-hot encoded):\")\n",
        "print(y_train[:5])\n",
        "\n",
        "print(\"Data cleaning and preparation complete.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukwKJaO817fy"
      },
      "source": [
        "# EXTRA DIFFERENT MODEL TRAIN THAT WORK PERFECTLY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZyLI3u7IzO7"
      },
      "source": [
        "## Fully Connected Feedforward Neural Network (MLP)\n",
        "fully connected feedforward neural network (also known as a multilayer perceptron or MLP)\n",
        "\n",
        "Fully Connected Feedforward Neural Network (MLP): This type of neural network consists of multiple layers where each neuron in one layer is connected to every neuron in the next layer. This architecture is suitable for tabular data and structured inputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CQmZ-4EQ82Mb",
        "outputId": "305700fc-7aa6-42ba-b6d0-b828ace686f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "111/111 - 2s - loss: 1.5533 - accuracy: 0.2751 - val_loss: 1.3351 - val_accuracy: 0.3694 - 2s/epoch - 20ms/step\n",
            "Epoch 2/100\n",
            "111/111 - 0s - loss: 1.3876 - accuracy: 0.3111 - val_loss: 1.3165 - val_accuracy: 0.4369 - 320ms/epoch - 3ms/step\n",
            "Epoch 3/100\n",
            "111/111 - 0s - loss: 1.3312 - accuracy: 0.3711 - val_loss: 1.2893 - val_accuracy: 0.4764 - 234ms/epoch - 2ms/step\n",
            "Epoch 4/100\n",
            "111/111 - 0s - loss: 1.3106 - accuracy: 0.3871 - val_loss: 1.2569 - val_accuracy: 0.4685 - 226ms/epoch - 2ms/step\n",
            "Epoch 5/100\n",
            "111/111 - 0s - loss: 1.2600 - accuracy: 0.4288 - val_loss: 1.2123 - val_accuracy: 0.5079 - 229ms/epoch - 2ms/step\n",
            "Epoch 6/100\n",
            "111/111 - 0s - loss: 1.2399 - accuracy: 0.4443 - val_loss: 1.1854 - val_accuracy: 0.5045 - 257ms/epoch - 2ms/step\n",
            "Epoch 7/100\n",
            "111/111 - 0s - loss: 1.2082 - accuracy: 0.4569 - val_loss: 1.1551 - val_accuracy: 0.5338 - 242ms/epoch - 2ms/step\n",
            "Epoch 8/100\n",
            "111/111 - 0s - loss: 1.1712 - accuracy: 0.4944 - val_loss: 1.1239 - val_accuracy: 0.5495 - 236ms/epoch - 2ms/step\n",
            "Epoch 9/100\n",
            "111/111 - 0s - loss: 1.1638 - accuracy: 0.4983 - val_loss: 1.1114 - val_accuracy: 0.5450 - 261ms/epoch - 2ms/step\n",
            "Epoch 10/100\n",
            "111/111 - 0s - loss: 1.1492 - accuracy: 0.5076 - val_loss: 1.1001 - val_accuracy: 0.5586 - 258ms/epoch - 2ms/step\n",
            "Epoch 11/100\n",
            "111/111 - 0s - loss: 1.1097 - accuracy: 0.5217 - val_loss: 1.0866 - val_accuracy: 0.5574 - 232ms/epoch - 2ms/step\n",
            "Epoch 12/100\n",
            "111/111 - 0s - loss: 1.1036 - accuracy: 0.5256 - val_loss: 1.0610 - val_accuracy: 0.5788 - 253ms/epoch - 2ms/step\n",
            "Epoch 13/100\n",
            "111/111 - 0s - loss: 1.0829 - accuracy: 0.5405 - val_loss: 1.0508 - val_accuracy: 0.5822 - 234ms/epoch - 2ms/step\n",
            "Epoch 14/100\n",
            "111/111 - 0s - loss: 1.0673 - accuracy: 0.5338 - val_loss: 1.0399 - val_accuracy: 0.5777 - 256ms/epoch - 2ms/step\n",
            "Epoch 15/100\n",
            "111/111 - 0s - loss: 1.0310 - accuracy: 0.5645 - val_loss: 1.0148 - val_accuracy: 0.5901 - 273ms/epoch - 2ms/step\n",
            "Epoch 16/100\n",
            "111/111 - 0s - loss: 1.0242 - accuracy: 0.5678 - val_loss: 1.0050 - val_accuracy: 0.6002 - 228ms/epoch - 2ms/step\n",
            "Epoch 17/100\n",
            "111/111 - 0s - loss: 1.0373 - accuracy: 0.5718 - val_loss: 1.0077 - val_accuracy: 0.6014 - 255ms/epoch - 2ms/step\n",
            "Epoch 18/100\n",
            "111/111 - 0s - loss: 1.0027 - accuracy: 0.5828 - val_loss: 0.9780 - val_accuracy: 0.6227 - 275ms/epoch - 2ms/step\n",
            "Epoch 19/100\n",
            "111/111 - 0s - loss: 0.9904 - accuracy: 0.5850 - val_loss: 0.9776 - val_accuracy: 0.6250 - 269ms/epoch - 2ms/step\n",
            "Epoch 20/100\n",
            "111/111 - 0s - loss: 0.9816 - accuracy: 0.5974 - val_loss: 0.9655 - val_accuracy: 0.6306 - 259ms/epoch - 2ms/step\n",
            "Epoch 21/100\n",
            "111/111 - 0s - loss: 0.9875 - accuracy: 0.5907 - val_loss: 0.9633 - val_accuracy: 0.6261 - 226ms/epoch - 2ms/step\n",
            "Epoch 22/100\n",
            "111/111 - 0s - loss: 0.9685 - accuracy: 0.5994 - val_loss: 0.9523 - val_accuracy: 0.6306 - 237ms/epoch - 2ms/step\n",
            "Epoch 23/100\n",
            "111/111 - 0s - loss: 0.9425 - accuracy: 0.6239 - val_loss: 0.9459 - val_accuracy: 0.6318 - 242ms/epoch - 2ms/step\n",
            "Epoch 24/100\n",
            "111/111 - 0s - loss: 0.9473 - accuracy: 0.6126 - val_loss: 0.9353 - val_accuracy: 0.6239 - 233ms/epoch - 2ms/step\n",
            "Epoch 25/100\n",
            "111/111 - 0s - loss: 0.9318 - accuracy: 0.6078 - val_loss: 0.9334 - val_accuracy: 0.6171 - 258ms/epoch - 2ms/step\n",
            "Epoch 26/100\n",
            "111/111 - 0s - loss: 0.9106 - accuracy: 0.6275 - val_loss: 0.9183 - val_accuracy: 0.6419 - 244ms/epoch - 2ms/step\n",
            "Epoch 27/100\n",
            "111/111 - 0s - loss: 0.9079 - accuracy: 0.6230 - val_loss: 0.9104 - val_accuracy: 0.6374 - 268ms/epoch - 2ms/step\n",
            "Epoch 28/100\n",
            "111/111 - 0s - loss: 0.8884 - accuracy: 0.6289 - val_loss: 0.8987 - val_accuracy: 0.6396 - 230ms/epoch - 2ms/step\n",
            "Epoch 29/100\n",
            "111/111 - 0s - loss: 0.8961 - accuracy: 0.6275 - val_loss: 0.9015 - val_accuracy: 0.6295 - 340ms/epoch - 3ms/step\n",
            "Epoch 30/100\n",
            "111/111 - 0s - loss: 0.8821 - accuracy: 0.6340 - val_loss: 0.8913 - val_accuracy: 0.6498 - 379ms/epoch - 3ms/step\n",
            "Epoch 31/100\n",
            "111/111 - 0s - loss: 0.8464 - accuracy: 0.6574 - val_loss: 0.8723 - val_accuracy: 0.6610 - 330ms/epoch - 3ms/step\n",
            "Epoch 32/100\n",
            "111/111 - 0s - loss: 0.8685 - accuracy: 0.6517 - val_loss: 0.8682 - val_accuracy: 0.6554 - 357ms/epoch - 3ms/step\n",
            "Epoch 33/100\n",
            "111/111 - 0s - loss: 0.8550 - accuracy: 0.6540 - val_loss: 0.8607 - val_accuracy: 0.6588 - 376ms/epoch - 3ms/step\n",
            "Epoch 34/100\n",
            "111/111 - 0s - loss: 0.8420 - accuracy: 0.6554 - val_loss: 0.8603 - val_accuracy: 0.6655 - 361ms/epoch - 3ms/step\n",
            "Epoch 35/100\n",
            "111/111 - 0s - loss: 0.8182 - accuracy: 0.6672 - val_loss: 0.8526 - val_accuracy: 0.6610 - 360ms/epoch - 3ms/step\n",
            "Epoch 36/100\n",
            "111/111 - 0s - loss: 0.8179 - accuracy: 0.6712 - val_loss: 0.8475 - val_accuracy: 0.6655 - 361ms/epoch - 3ms/step\n",
            "Epoch 37/100\n",
            "111/111 - 0s - loss: 0.8236 - accuracy: 0.6692 - val_loss: 0.8575 - val_accuracy: 0.6430 - 383ms/epoch - 3ms/step\n",
            "Epoch 38/100\n",
            "111/111 - 0s - loss: 0.8141 - accuracy: 0.6644 - val_loss: 0.8463 - val_accuracy: 0.6723 - 311ms/epoch - 3ms/step\n",
            "Epoch 39/100\n",
            "111/111 - 0s - loss: 0.8037 - accuracy: 0.6802 - val_loss: 0.8320 - val_accuracy: 0.6667 - 271ms/epoch - 2ms/step\n",
            "Epoch 40/100\n",
            "111/111 - 0s - loss: 0.7931 - accuracy: 0.6782 - val_loss: 0.8342 - val_accuracy: 0.6610 - 227ms/epoch - 2ms/step\n",
            "Epoch 41/100\n",
            "111/111 - 0s - loss: 0.8012 - accuracy: 0.6872 - val_loss: 0.8303 - val_accuracy: 0.6610 - 231ms/epoch - 2ms/step\n",
            "Epoch 42/100\n",
            "111/111 - 0s - loss: 0.7933 - accuracy: 0.6827 - val_loss: 0.8162 - val_accuracy: 0.6779 - 242ms/epoch - 2ms/step\n",
            "Epoch 43/100\n",
            "111/111 - 0s - loss: 0.7843 - accuracy: 0.6937 - val_loss: 0.8171 - val_accuracy: 0.6723 - 271ms/epoch - 2ms/step\n",
            "Epoch 44/100\n",
            "111/111 - 0s - loss: 0.7801 - accuracy: 0.6909 - val_loss: 0.8123 - val_accuracy: 0.6824 - 232ms/epoch - 2ms/step\n",
            "Epoch 45/100\n",
            "111/111 - 0s - loss: 0.7733 - accuracy: 0.6900 - val_loss: 0.8089 - val_accuracy: 0.6791 - 238ms/epoch - 2ms/step\n",
            "Epoch 46/100\n",
            "111/111 - 0s - loss: 0.7545 - accuracy: 0.6965 - val_loss: 0.8020 - val_accuracy: 0.6824 - 248ms/epoch - 2ms/step\n",
            "Epoch 47/100\n",
            "111/111 - 0s - loss: 0.7592 - accuracy: 0.7033 - val_loss: 0.7960 - val_accuracy: 0.6869 - 274ms/epoch - 2ms/step\n",
            "Epoch 48/100\n",
            "111/111 - 0s - loss: 0.7431 - accuracy: 0.7050 - val_loss: 0.7978 - val_accuracy: 0.6903 - 257ms/epoch - 2ms/step\n",
            "Epoch 49/100\n",
            "111/111 - 0s - loss: 0.7443 - accuracy: 0.7038 - val_loss: 0.7959 - val_accuracy: 0.6723 - 235ms/epoch - 2ms/step\n",
            "Epoch 50/100\n",
            "111/111 - 0s - loss: 0.7421 - accuracy: 0.7111 - val_loss: 0.7879 - val_accuracy: 0.6914 - 233ms/epoch - 2ms/step\n",
            "Epoch 51/100\n",
            "111/111 - 0s - loss: 0.7354 - accuracy: 0.7066 - val_loss: 0.7966 - val_accuracy: 0.6779 - 259ms/epoch - 2ms/step\n",
            "Epoch 52/100\n",
            "111/111 - 0s - loss: 0.7324 - accuracy: 0.7142 - val_loss: 0.7864 - val_accuracy: 0.6892 - 251ms/epoch - 2ms/step\n",
            "Epoch 53/100\n",
            "111/111 - 0s - loss: 0.7248 - accuracy: 0.7204 - val_loss: 0.7828 - val_accuracy: 0.6881 - 228ms/epoch - 2ms/step\n",
            "Epoch 54/100\n",
            "111/111 - 0s - loss: 0.7073 - accuracy: 0.7202 - val_loss: 0.7813 - val_accuracy: 0.6993 - 297ms/epoch - 3ms/step\n",
            "Epoch 55/100\n",
            "111/111 - 0s - loss: 0.6986 - accuracy: 0.7297 - val_loss: 0.7811 - val_accuracy: 0.7027 - 265ms/epoch - 2ms/step\n",
            "Epoch 56/100\n",
            "111/111 - 0s - loss: 0.7114 - accuracy: 0.7188 - val_loss: 0.7874 - val_accuracy: 0.6959 - 222ms/epoch - 2ms/step\n",
            "Epoch 57/100\n",
            "111/111 - 0s - loss: 0.6959 - accuracy: 0.7213 - val_loss: 0.7853 - val_accuracy: 0.6937 - 227ms/epoch - 2ms/step\n",
            "Epoch 58/100\n",
            "111/111 - 0s - loss: 0.6922 - accuracy: 0.7292 - val_loss: 0.7807 - val_accuracy: 0.6892 - 261ms/epoch - 2ms/step\n",
            "Epoch 59/100\n",
            "111/111 - 0s - loss: 0.7112 - accuracy: 0.7218 - val_loss: 0.7831 - val_accuracy: 0.6892 - 259ms/epoch - 2ms/step\n",
            "Epoch 60/100\n",
            "111/111 - 0s - loss: 0.7059 - accuracy: 0.7162 - val_loss: 0.7877 - val_accuracy: 0.6836 - 250ms/epoch - 2ms/step\n",
            "Epoch 61/100\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-9da0e7bb50c6>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m history = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n\u001b[0m\u001b[1;32m     24\u001b[0m                     epochs=100, batch_size=32, callbacks=[early_stopping], verbose=2)\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Build the deep learning model\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_shape=(X_train.shape[1],), activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define early stopping to prevent overfitting\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
        "                    epochs=100, batch_size=32, callbacks=[early_stopping], verbose=2)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f'Deep Learning Model Accuracy: {accuracy:.2f}')\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_test_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Classification report\n",
        "report = classification_report(y_test_classes, y_pred_classes)\n",
        "print('Deep Learning Model Classification Report:')\n",
        "print(report)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIlBdCh8I3B-"
      },
      "source": [
        "## Enhanced MLP Neural Network Model | 73% Accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LukGZneI5CZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "# Define the neural network structure\n",
        "model = Sequential([\n",
        "    Dense(256, input_shape=(X_train.shape[1],), activation='relu', kernel_regularizer=l2(0.001)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(128, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(64, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "    Dropout(0.5),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model with optimization setup\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Setup early stopping to prevent overfitting\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# Train the model with training data and validate with testing data\n",
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
        "                    epochs=200, batch_size=64, callbacks=[early_stopping], verbose=2)\n",
        "\n",
        "# Evaluate the model performance on the test set\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f'Enhanced Model Accuracy: {accuracy:.2f}')\n",
        "\n",
        "# Predict the test set results\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_test_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Generate a classification report\n",
        "from sklearn.metrics import classification_report\n",
        "report = classification_report(y_test_classes, y_pred_classes)\n",
        "print('Enhanced Deep Learning Model Classification Report:')\n",
        "print(report)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "wsWpJFthsGYZ",
        "fnA0X7PCAubW",
        "0mhyEUawQwrC",
        "cwK2si4QAXfE",
        "u0B9nIR6zLri",
        "ukwKJaO817fy",
        "4ZyLI3u7IzO7",
        "xIlBdCh8I3B-"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}